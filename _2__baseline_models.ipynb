{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb718e9f-fd18-4ac5-8519-d445a9c1be27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/valeriya/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvslovik\u001b[0m (\u001b[33mhomeserve\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b17e3-ef79-4dd5-86f9-29ef9e6eadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import json\n",
    "import pickle\n",
    "from etl.util import prepare_dataset_without_leakage\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING MODELS WITHOUT DATA LEAKAGE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîÑ Preparing datasets with proper time-based features...\")\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "customer_lifetime = pd.read_csv('customer_lifetime_data.csv')\n",
    "opportunity_30day = pd.read_csv('30day_opportunities_data.csv')\n",
    "product_sessions = pd.read_csv('product_sessions_data.csv')\n",
    "\n",
    "datasets_fixed = {\n",
    "    'Customer Lifetime': prepare_dataset_without_leakage(customer_lifetime, 'Customer Lifetime'),\n",
    "    '30-Day Windows': prepare_dataset_without_leakage(opportunity_30day, '30-Day Windows'),\n",
    "    'Product Sessions': prepare_dataset_without_leakage(product_sessions, 'Product Sessions')\n",
    "}\n",
    "\n",
    "# Re-train models\n",
    "results_fixed = {}\n",
    "\n",
    "for dataset_name, (X, y) in datasets_fixed.items():\n",
    "    print(f\"\\nüéØ Re-training {dataset_name} ({len(X):,} samples)...\")\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Train Random Forest (better for non-linear relationships)\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,  # Reduced to prevent overfitting\n",
    "        min_samples_split=50,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    rf_y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    rf_auc = roc_auc_score(y_test, rf_y_pred_proba)\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    results_fixed[dataset_name] = {\n",
    "        'AUC': rf_auc,\n",
    "        'Top Features': feature_importance.head(5)['feature'].tolist(),\n",
    "        'Feature Importances': feature_importance.head(10),\n",
    "        'Sample Size': len(X),\n",
    "        'Conversion Rate': y.mean()\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úì Fixed Random Forest AUC: {rf_auc:.3f}\")\n",
    "    print(f\"  ‚úì Top 3 features: {feature_importance.head(3)['feature'].tolist()}\")\n",
    "\n",
    "# Performance Comparison After Fix\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REALISTIC PERFORMANCE COMPARISON (NO LEAKAGE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_fixed = []\n",
    "for dataset_name, result in results_fixed.items():\n",
    "    comparison_fixed.append({\n",
    "        'Aggregation Strategy': dataset_name,\n",
    "        'Samples': f\"{result['Sample Size']:,}\",\n",
    "        'Conv Rate': f\"{result['Conversion Rate']:.1%}\",\n",
    "        'Realistic AUC': f\"{result['AUC']:.3f}\",\n",
    "        'Top Feature': result['Top Features'][0] if result['Top Features'] else 'N/A'\n",
    "    })\n",
    "\n",
    "comparison_fixed_df = pd.DataFrame(comparison_fixed)\n",
    "comparison_fixed_df = comparison_fixed_df.sort_values('Realistic AUC', ascending=False)\n",
    "\n",
    "print(\"\\nüìà REALISTIC PERFORMANCE RANKING:\")\n",
    "for i, row in comparison_fixed_df.iterrows():\n",
    "    print(f\"{i+1}. {row['Aggregation Strategy']}:\")\n",
    "    print(f\"   Conversion Rate: {row['Conv Rate']}\")\n",
    "    print(f\"   Realistic AUC: {row['Realistic AUC']}\")\n",
    "    print(f\"   Top Feature: {row['Top Feature']}\")\n",
    "    print()\n",
    "\n",
    "# Find best realistic strategy\n",
    "best_realistic_strategy = comparison_fixed_df.iloc[0]['Aggregation Strategy']\n",
    "best_realistic_auc = float(comparison_fixed_df.iloc[0]['Realistic AUC'].replace('%', ''))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUSINESS INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüèÜ REAL BEST STRATEGY: {best_realistic_strategy}\")\n",
    "print(f\"   Realistic AUC: {best_realistic_auc:.3f}\")\n",
    "print(f\"   (Previous inflated AUC: 0.982 ‚Üí Real AUC: {best_realistic_auc:.3f})\")\n",
    "\n",
    "print(f\"\\nüîç REAL TOP CONVERSION DRIVERS:\")\n",
    "if best_realistic_strategy in results_fixed:\n",
    "    top_features = results_fixed[best_realistic_strategy]['Top Features']\n",
    "    for i, feature in enumerate(top_features[:5], 1):\n",
    "        print(f\"   {i}. {feature}\")\n",
    "\n",
    "# Save the realistic model\n",
    "if best_realistic_strategy in datasets_fixed:\n",
    "    X, y = datasets_fixed[best_realistic_strategy]\n",
    "    \n",
    "    # Train final model on full data\n",
    "    final_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        min_samples_split=50,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    final_model.fit(X, y)\n",
    "    \n",
    "    # Save model and feature names\n",
    "    model_data = {\n",
    "        'model': final_model,\n",
    "        'feature_names': X.columns.tolist(),\n",
    "        'aggregation_strategy': best_realistic_strategy,\n",
    "        'realistic_auc': best_realistic_auc\n",
    "    }\n",
    "    \n",
    "    with open('realistic_conversion_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model_data, f)\n",
    "    \n",
    "    print(f\"‚úì Realistic model saved for {best_realistic_strategy}\")\n",
    "    print(f\"‚úì Realistic AUC: {best_realistic_auc:.3f}\")\n",
    "    print(f\"‚úì Features used: {len(X.columns)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[Poetry] ai-france-hvac",
   "language": "python",
   "name": "ai-france-hvac-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
