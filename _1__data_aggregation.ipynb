{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282482b1-6fa0-485f-8eb7-d20346f8d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "IMPLEMENTING 3 AGGREGATION STRATEGIES\n",
      "================================================================================\n",
      "Loaded clean data: 38,333 quotes from 25,930 customers\n",
      "\n",
      "================================================================================\n",
      "STRATEGY 1: CUSTOMER LIFETIME (Ever bought?)\n",
      "================================================================================\n",
      "Customer-level dataset created: 25,930 customers\n",
      "Conversion rate: 41.2%\n",
      "Avg quotes per customer: 1.48\n",
      "Sample features: ['numero_compte', 'converted', 'avg_quote_amount', 'min_quote_amount', 'max_quote_amount', 'std_quote_amount', 'total_quotes', 'main_region']...\n",
      "\n",
      "================================================================================\n",
      "STRATEGY 2: 30-DAY ROLLING WINDOWS\n",
      "================================================================================\n",
      "30-day opportunities created: 28,648 opportunities\n",
      "Conversion rate: 39.3%\n",
      "Avg quotes per opportunity: 1.34\n",
      "Avg opportunity duration: 2.0 days\n",
      "\n",
      "================================================================================\n",
      "STRATEGY 3: PRODUCT SESSION GROUPS\n",
      "================================================================================\n",
      "Product sessions created: 30,109 sessions\n",
      "Conversion rate: 38.2%\n",
      "Avg quotes per session: 1.27\n",
      "Avg session duration: 3.1 days\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: ALL 3 STRATEGIES COMPARISON\n",
      "================================================================================\n",
      "         Strategy  Units Conversion Rate Avg Quotes/Unit Sample Size\n",
      "Customer Lifetime  25930           41.2%            1.48      25,930\n",
      "   30-Day Windows  28648           39.3%            1.34      28,648\n",
      " Product Sessions  30109           38.2%            1.27      30,109\n",
      "\n",
      "ðŸ’¾ SAVING AGGREGATED DATASETS\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"IMPLEMENTING 3 AGGREGATION STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the clean data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "df_clean = pd.read_csv('cleaned_quote_data.csv')\n",
    "df_clean['dt_creation_devis'] = pd.to_datetime(df_clean['dt_creation_devis'])\n",
    "print(f\"Loaded clean data: {len(df_clean):,} quotes from {df_clean['numero_compte'].nunique():,} customers\")\n",
    "\n",
    "# Strategy 1: Customer Lifetime Aggregation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY 1: CUSTOMER LIFETIME (Ever bought?)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def aggregate_customer_lifetime(df):\n",
    "    \"\"\"\n",
    "    Aggregate at customer level: Did they EVER buy from us?\n",
    "    \"\"\"\n",
    "    # Group by customer\n",
    "    customer_data = df.groupby('numero_compte').agg({\n",
    "        'fg_devis_accepte': 'max',  # 1 if any quote converted\n",
    "        'mt_apres_remise_ht_devis': ['mean', 'min', 'max', 'std', 'count'],\n",
    "        'nom_region': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'missing',\n",
    "        'nom_agence': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'missing',\n",
    "        'famille_equipement_produit': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'missing',\n",
    "        'dt_creation_devis': ['min', 'max']  # First and last quote dates\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    customer_data.columns = [\n",
    "        'converted',\n",
    "        'avg_quote_amount', 'min_quote_amount', 'max_quote_amount', \n",
    "        'std_quote_amount', 'total_quotes',\n",
    "        'main_region', 'main_agency', 'main_product_family',\n",
    "        'first_quote_date', 'last_quote_date'\n",
    "    ]\n",
    "    \n",
    "    # Calculate additional features\n",
    "    customer_data = customer_data.reset_index()\n",
    "    customer_data['customer_duration_days'] = (\n",
    "        pd.to_datetime(customer_data['last_quote_date']) - \n",
    "        pd.to_datetime(customer_data['first_quote_date'])\n",
    "    ).dt.days + 1\n",
    "    \n",
    "    customer_data['quotes_per_month'] = (\n",
    "        customer_data['total_quotes'] / (customer_data['customer_duration_days'] / 30.44)\n",
    "    ).fillna(0)\n",
    "    \n",
    "    customer_data['price_range'] = customer_data['max_quote_amount'] - customer_data['min_quote_amount']\n",
    "    \n",
    "    return customer_data\n",
    "\n",
    "# Apply Strategy 1\n",
    "customer_lifetime_df = aggregate_customer_lifetime(df_clean)\n",
    "print(f\"Customer-level dataset created: {len(customer_lifetime_df):,} customers\")\n",
    "print(f\"Conversion rate: {customer_lifetime_df['converted'].mean():.1%}\")\n",
    "print(f\"Avg quotes per customer: {customer_lifetime_df['total_quotes'].mean():.2f}\")\n",
    "print(f\"Sample features: {list(customer_lifetime_df.columns)[:8]}...\")\n",
    "\n",
    "# Strategy 2: 30-Day Rolling Windows\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY 2: 30-DAY ROLLING WINDOWS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def aggregate_30day_windows(df, window_days=30):\n",
    "    \"\"\"\n",
    "    Group quotes within 30 days as one opportunity\n",
    "    \"\"\"\n",
    "    # Sort by customer and date\n",
    "    df = df.sort_values(['numero_compte', 'dt_creation_devis']).copy()\n",
    "    \n",
    "    # Calculate days since last quote for each customer\n",
    "    df['days_since_last'] = df.groupby('numero_compte')['dt_creation_devis'].diff().dt.days\n",
    "    \n",
    "    # New opportunity if gap > 30 days or first quote\n",
    "    df['new_opportunity'] = (df['days_since_last'] > window_days) | df['days_since_last'].isna()\n",
    "    \n",
    "    # Create opportunity IDs\n",
    "    df['opportunity_id'] = df.groupby('numero_compte')['new_opportunity'].cumsum()\n",
    "    df['customer_opportunity_id'] = df['numero_compte'] + '_opp_' + df['opportunity_id'].astype(str)\n",
    "    \n",
    "    # Aggregate by opportunity\n",
    "    opportunity_data = df.groupby(['numero_compte', 'opportunity_id', 'customer_opportunity_id']).agg({\n",
    "        'fg_devis_accepte': 'max',  # 1 if any quote in opportunity converted\n",
    "        'mt_apres_remise_ht_devis': ['mean', 'min', 'max', 'count', 'std'],\n",
    "        'dt_creation_devis': ['min', 'max'],  # Opportunity timeframe\n",
    "        'famille_equipement_produit': lambda x: list(x.unique()),  # Products considered\n",
    "        'nom_region': 'first',  # Assuming region constant per opportunity\n",
    "        'nom_agence': 'first'   # Assuming agency constant\n",
    "    })\n",
    "    \n",
    "    # Flatten columns\n",
    "    opportunity_data.columns = [\n",
    "        'converted',\n",
    "        'avg_price', 'min_price', 'max_price', 'quote_count', 'price_std',\n",
    "        'start_date', 'end_date',\n",
    "        'products_considered', 'region', 'agency'\n",
    "    ]\n",
    "    \n",
    "    opportunity_data = opportunity_data.reset_index()\n",
    "    \n",
    "    # Calculate opportunity features\n",
    "    opportunity_data['opportunity_duration_days'] = (\n",
    "        pd.to_datetime(opportunity_data['end_date']) - \n",
    "        pd.to_datetime(opportunity_data['start_date'])\n",
    "    ).dt.days + 1\n",
    "    \n",
    "    opportunity_data['quotes_per_day'] = opportunity_data['quote_count'] / opportunity_data['opportunity_duration_days']\n",
    "    opportunity_data['price_range'] = opportunity_data['max_price'] - opportunity_data['min_price']\n",
    "    opportunity_data['product_variety'] = opportunity_data['products_considered'].apply(len)\n",
    "    \n",
    "    # Add customer-level context\n",
    "    customer_stats = df.groupby('numero_compte').agg({\n",
    "        'fg_devis_accepte': 'sum',\n",
    "        'mt_apres_remise_ht_devis': 'mean'\n",
    "    }).rename(columns={\n",
    "        'fg_devis_accepte': 'customer_total_sales',\n",
    "        'mt_apres_remise_ht_devis': 'customer_avg_price'\n",
    "    })\n",
    "    \n",
    "    opportunity_data = opportunity_data.merge(customer_stats, on='numero_compte', how='left')\n",
    "    \n",
    "    return opportunity_data\n",
    "\n",
    "# Apply Strategy 2\n",
    "opportunity_30day_df = aggregate_30day_windows(df_clean, window_days=30)\n",
    "print(f\"30-day opportunities created: {len(opportunity_30day_df):,} opportunities\")\n",
    "print(f\"Conversion rate: {opportunity_30day_df['converted'].mean():.1%}\")\n",
    "print(f\"Avg quotes per opportunity: {opportunity_30day_df['quote_count'].mean():.2f}\")\n",
    "print(f\"Avg opportunity duration: {opportunity_30day_df['opportunity_duration_days'].mean():.1f} days\")\n",
    "\n",
    "# Strategy 3: Product Session Groups\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY 3: PRODUCT SESSION GROUPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def aggregate_product_sessions(df):\n",
    "    \"\"\"\n",
    "    Group quotes by product family changes\n",
    "    New opportunity when product family changes\n",
    "    \"\"\"\n",
    "    # Sort by customer and date\n",
    "    df = df.sort_values(['numero_compte', 'dt_creation_devis']).copy()\n",
    "    \n",
    "    # Track product family changes\n",
    "    df['prev_product_family'] = df.groupby('numero_compte')['famille_equipement_produit'].shift()\n",
    "    df['product_changed'] = df['famille_equipement_produit'] != df['prev_product_family']\n",
    "    \n",
    "    # Also consider time gaps > 90 days as new session\n",
    "    df['days_since_last'] = df.groupby('numero_compte')['dt_creation_devis'].diff().dt.days\n",
    "    df['long_gap'] = df['days_since_last'] > 90\n",
    "    \n",
    "    # New session if product changed OR long gap OR first quote\n",
    "    df['new_session'] = df['product_changed'] | df['long_gap'] | df['days_since_last'].isna()\n",
    "    \n",
    "    # Create session IDs\n",
    "    df['session_id'] = df.groupby('numero_compte')['new_session'].cumsum()\n",
    "    df['customer_session_id'] = df['numero_compte'] + '_session_' + df['session_id'].astype(str)\n",
    "    \n",
    "    # Aggregate by session\n",
    "    session_data = df.groupby(['numero_compte', 'session_id', 'customer_session_id']).agg({\n",
    "        'fg_devis_accepte': 'max',  # 1 if any quote in session converted\n",
    "        'mt_apres_remise_ht_devis': ['mean', 'min', 'max', 'count', 'std'],\n",
    "        'dt_creation_devis': ['min', 'max'],\n",
    "        'famille_equipement_produit': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'mixed',\n",
    "        'type_equipement_produit': lambda x: list(x.unique())[:3],  # Top 3 product types\n",
    "        'nom_region': 'first',\n",
    "        'nom_agence': 'first'\n",
    "    })\n",
    "    \n",
    "    # Flatten columns\n",
    "    session_data.columns = [\n",
    "        'converted',\n",
    "        'avg_price', 'min_price', 'max_price', 'quote_count', 'price_std',\n",
    "        'start_date', 'end_date',\n",
    "        'main_product_family', 'product_types', 'region', 'agency'\n",
    "    ]\n",
    "    \n",
    "    session_data = session_data.reset_index()\n",
    "    \n",
    "    # Calculate session features\n",
    "    session_data['session_duration_days'] = (\n",
    "        pd.to_datetime(session_data['end_date']) - \n",
    "        pd.to_datetime(session_data['start_date'])\n",
    "    ).dt.days + 1\n",
    "    \n",
    "    session_data['quotes_per_day'] = session_data['quote_count'] / session_data['session_duration_days']\n",
    "    session_data['price_range'] = session_data['max_price'] - session_data['min_price']\n",
    "    session_data['product_type_count'] = session_data['product_types'].apply(len)\n",
    "    \n",
    "    # Add customer-level context\n",
    "    customer_stats = df.groupby('numero_compte').agg({\n",
    "        'fg_devis_accepte': 'sum',\n",
    "        'famille_equipement_produit': 'nunique'\n",
    "    }).rename(columns={\n",
    "        'fg_devis_accepte': 'customer_total_sales',\n",
    "        'famille_equipement_produit': 'customer_product_variety'\n",
    "    })\n",
    "    \n",
    "    session_data = session_data.merge(customer_stats, on='numero_compte', how='left')\n",
    "    \n",
    "    return session_data\n",
    "\n",
    "# Apply Strategy 3\n",
    "product_sessions_df = aggregate_product_sessions(df_clean)\n",
    "print(f\"Product sessions created: {len(product_sessions_df):,} sessions\")\n",
    "print(f\"Conversion rate: {product_sessions_df['converted'].mean():.1%}\")\n",
    "print(f\"Avg quotes per session: {product_sessions_df['quote_count'].mean():.2f}\")\n",
    "print(f\"Avg session duration: {product_sessions_df['session_duration_days'].mean():.1f} days\")\n",
    "\n",
    "# Summary Comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: ALL 3 STRATEGIES COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = {\n",
    "    'Strategy': ['Customer Lifetime', '30-Day Windows', 'Product Sessions'],\n",
    "    'Units': [len(customer_lifetime_df), len(opportunity_30day_df), len(product_sessions_df)],\n",
    "    'Conversion Rate': [\n",
    "        f\"{customer_lifetime_df['converted'].mean():.1%}\",\n",
    "        f\"{opportunity_30day_df['converted'].mean():.1%}\",\n",
    "        f\"{product_sessions_df['converted'].mean():.1%}\"\n",
    "    ],\n",
    "    'Avg Quotes/Unit': [\n",
    "        f\"{customer_lifetime_df['total_quotes'].mean():.2f}\",\n",
    "        f\"{opportunity_30day_df['quote_count'].mean():.2f}\",\n",
    "        f\"{product_sessions_df['quote_count'].mean():.2f}\"\n",
    "    ],\n",
    "    'Sample Size': [\n",
    "        f\"{len(customer_lifetime_df):,}\",\n",
    "        f\"{len(opportunity_30day_df):,}\",\n",
    "        f\"{len(product_sessions_df):,}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save all datasets for Day 3\n",
    "print(\"\\nðŸ’¾ SAVING AGGREGATED DATASETS\")\n",
    "customer_lifetime_df.to_csv('customer_lifetime_data.csv', index=False)\n",
    "opportunity_30day_df.to_csv('30day_opportunities_data.csv', index=False)\n",
    "product_sessions_df.to_csv('product_sessions_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
