{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac937c8-9721-40d2-a2f9-8c524f6137ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /home/valeriya/project/homeserve/credit_policy/.direnv/python-3.12.0/bin/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/valeriya/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvslovik\u001b[0m (\u001b[33mhomeserve\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "# Should point to poetry's virtual environment\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa101db3-5e56-4244-be2f-c7f2631b0855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING MODELS WITHOUT DATA LEAKAGE\n",
      "================================================================================\n",
      "\n",
      "üîó Initializing Weights & Biases tracking...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/valeriya/project/homeserve/ai-france-hvac/wandb/run-20260118_231614-cdt74l71</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/homeserve/france-hvac/runs/cdt74l71' target=\"_blank\">credit-policy-realistic-models</a></strong> to <a href='https://wandb.ai/homeserve/france-hvac' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/homeserve/france-hvac' target=\"_blank\">https://wandb.ai/homeserve/france-hvac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/homeserve/france-hvac/runs/cdt74l71' target=\"_blank\">https://wandb.ai/homeserve/france-hvac/runs/cdt74l71</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Wandb initialized. Run URL: https://wandb.ai/homeserve/france-hvac/runs/cdt74l71\n",
      "\n",
      "üîÑ Preparing datasets with proper time-based features...\n",
      "\n",
      "üìä Re-preparing Customer Lifetime without leakage...\n",
      "  Features after removing leakage: 10\n",
      "  Removed leaky features: []\n",
      "\n",
      "üìä Re-preparing 30-Day Windows without leakage...\n",
      "  Features after removing leakage: 11\n",
      "  Removed leaky features: ['customer_total_sales', 'customer_avg_price', 'products_considered']\n",
      "\n",
      "üìä Re-preparing Product Sessions without leakage...\n",
      "  Features after removing leakage: 11\n",
      "  Removed leaky features: ['customer_total_sales', 'customer_product_variety', 'product_types']\n",
      "\n",
      "üéØ Re-training Customer Lifetime (25,930 samples)...\n",
      "  Note: Could not plot ROC for Customer Lifetime\n",
      "  ‚úì Fixed Random Forest AUC: 0.660\n",
      "  ‚úì Top 3 features: ['customer_duration_days', 'quotes_per_month', 'min_quote_amount']\n",
      "\n",
      "üéØ Re-training 30-Day Windows (28,648 samples)...\n",
      "  Note: Could not plot ROC for 30-Day Windows\n",
      "  ‚úì Fixed Random Forest AUC: 0.618\n",
      "  ‚úì Top 3 features: ['max_price', 'min_price', 'avg_price']\n",
      "\n",
      "üéØ Re-training Product Sessions (30,109 samples)...\n",
      "  Note: Could not plot ROC for Product Sessions\n",
      "  ‚úì Fixed Random Forest AUC: 0.623\n",
      "  ‚úì Top 3 features: ['min_price', 'max_price', 'avg_price']\n",
      "\n",
      "üìä Creating model comparison dashboard...\n",
      "\n",
      "================================================================================\n",
      "REALISTIC PERFORMANCE COMPARISON (NO LEAKAGE)\n",
      "================================================================================\n",
      "\n",
      "üìà REALISTIC PERFORMANCE RANKING:\n",
      "1. Customer Lifetime:\n",
      "   Conversion Rate: 41.2%\n",
      "   Realistic AUC: 0.660\n",
      "   Accuracy: 0.632\n",
      "   F1 Score: 0.526\n",
      "   Top Feature: customer_duration_days\n",
      "\n",
      "3. Product Sessions:\n",
      "   Conversion Rate: 38.2%\n",
      "   Realistic AUC: 0.623\n",
      "   Accuracy: 0.598\n",
      "   F1 Score: 0.506\n",
      "   Top Feature: min_price\n",
      "\n",
      "2. 30-Day Windows:\n",
      "   Conversion Rate: 39.3%\n",
      "   Realistic AUC: 0.618\n",
      "   Accuracy: 0.602\n",
      "   F1 Score: 0.510\n",
      "   Top Feature: max_price\n",
      "\n",
      "\n",
      "================================================================================\n",
      "BUSINESS INSIGHTS\n",
      "================================================================================\n",
      "\n",
      "üèÜ REAL BEST STRATEGY: Customer Lifetime\n",
      "   Realistic AUC: 0.660\n",
      "\n",
      "üîç REAL TOP CONVERSION DRIVERS:\n",
      "   1. customer_duration_days\n",
      "   2. quotes_per_month\n",
      "   3. min_quote_amount\n",
      "   4. avg_quote_amount\n",
      "   5. max_quote_amount\n",
      "\n",
      "üíæ Saving best model...\n",
      "‚úì Model saved: realistic_conversion_model.pkl\n",
      "‚úì Strategy: Customer Lifetime\n",
      "‚úì Realistic AUC: 0.660\n",
      "‚úì Features used: 10\n",
      "\n",
      "üì§ Logging model to wandb...\n",
      "‚úì Model logged to wandb as artifact\n",
      "‚úì Feature importance saved: feature_importance.csv\n",
      "\n",
      "================================================================================\n",
      "WANDB TRACKING COMPLETE\n",
      "================================================================================\n",
      "‚úÖ Run complete! View results at: https://wandb.ai/homeserve/france-hvac/runs/cdt74l71\n",
      "üìä Project: france-hvac\n",
      "üè∑Ô∏è  Run name: credit-policy-realistic-models\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>30-Day Windows/accuracy</td><td>‚ñÅ</td></tr><tr><td>30-Day Windows/auc</td><td>‚ñÅ</td></tr><tr><td>30-Day Windows/conversion_rate</td><td>‚ñÅ</td></tr><tr><td>30-Day Windows/dataset_size</td><td>‚ñÅ</td></tr><tr><td>30-Day Windows/f1</td><td>‚ñÅ</td></tr><tr><td>30-Day Windows/n_features</td><td>‚ñÅ</td></tr><tr><td>30-Day Windows/precision</td><td>‚ñÅ</td></tr><tr><td>30-Day Windows/recall</td><td>‚ñÅ</td></tr><tr><td>30-Day Windows/test_size</td><td>‚ñÅ</td></tr><tr><td>30-Day Windows/train_size</td><td>‚ñÅ</td></tr><tr><td>+20</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>30-Day Windows/accuracy</td><td>0.60157</td></tr><tr><td>30-Day Windows/auc</td><td>0.61843</td></tr><tr><td>30-Day Windows/conversion_rate</td><td>0.39298</td></tr><tr><td>30-Day Windows/dataset_size</td><td>28648</td></tr><tr><td>30-Day Windows/f1</td><td>0.50998</td></tr><tr><td>30-Day Windows/n_features</td><td>11</td></tr><tr><td>30-Day Windows/precision</td><td>0.49356</td></tr><tr><td>30-Day Windows/recall</td><td>0.52753</td></tr><tr><td>30-Day Windows/test_size</td><td>5730</td></tr><tr><td>30-Day Windows/train_size</td><td>22918</td></tr><tr><td>+30</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">credit-policy-realistic-models</strong> at: <a href='https://wandb.ai/homeserve/france-hvac/runs/cdt74l71' target=\"_blank\">https://wandb.ai/homeserve/france-hvac/runs/cdt74l71</a><br> View project at: <a href='https://wandb.ai/homeserve/france-hvac' target=\"_blank\">https://wandb.ai/homeserve/france-hvac</a><br>Synced 4 W&B file(s), 7 media file(s), 14 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260118_231614-cdt74l71/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Wandb run finished successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import json\n",
    "import pickle\n",
    "from etl.util import prepare_dataset_without_leakage\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============ ADD WANDB IMPORTS ============\n",
    "import wandb\n",
    "from wandb.sklearn import plot_roc, plot_confusion_matrix, plot_precision_recall, plot_feature_importances\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING MODELS WITHOUT DATA LEAKAGE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============ INITIALIZE WANDB ============\n",
    "print(\"\\nüîó Initializing Weights & Biases tracking...\")\n",
    "wandb.init(\n",
    "    project=\"france-hvac\",  # Your project name\n",
    "    name=\"credit-policy-realistic-models\",\n",
    "    config={\n",
    "        \"test_size\": 0.2,\n",
    "        \"random_state\": 42,\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 8,\n",
    "        \"min_samples_split\": 50,\n",
    "        \"class_weight\": \"balanced\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"stratify\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Access config\n",
    "config = wandb.config\n",
    "print(f\"‚úì Wandb initialized. Run URL: {wandb.run.get_url()}\")\n",
    "\n",
    "print(\"\\nüîÑ Preparing datasets with proper time-based features...\")\n",
    "\n",
    "# Load datasets\n",
    "customer_lifetime = pd.read_csv('customer_lifetime_data.csv')\n",
    "opportunity_30day = pd.read_csv('30day_opportunities_data.csv')\n",
    "product_sessions = pd.read_csv('product_sessions_data.csv')\n",
    "\n",
    "datasets_fixed = {\n",
    "    'Customer Lifetime': prepare_dataset_without_leakage(customer_lifetime, 'Customer Lifetime'),\n",
    "    '30-Day Windows': prepare_dataset_without_leakage(opportunity_30day, '30-Day Windows'),\n",
    "    'Product Sessions': prepare_dataset_without_leakage(product_sessions, 'Product Sessions')\n",
    "}\n",
    "\n",
    "# Re-train models\n",
    "results_fixed = {}\n",
    "run_metrics = []  # Store metrics for wandb comparison\n",
    "\n",
    "for dataset_name, (X, y) in datasets_fixed.items():\n",
    "    print(f\"\\nüéØ Re-training {dataset_name} ({len(X):,} samples)...\")\n",
    "    \n",
    "    # ============ LOG DATASET INFO TO WANDB ============\n",
    "    wandb.log({\n",
    "        f\"{dataset_name}/dataset_size\": len(X),\n",
    "        f\"{dataset_name}/conversion_rate\": y.mean(),\n",
    "        f\"{dataset_name}/n_features\": X.shape[1]\n",
    "    })\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=config.test_size, random_state=config.random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=config.n_estimators,\n",
    "        max_depth=config.max_depth,\n",
    "        min_samples_split=config.min_samples_split,\n",
    "        class_weight=config.class_weight,\n",
    "        random_state=config.random_state,\n",
    "        n_jobs=config.n_jobs\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    rf_y_pred = rf_model.predict(X_test)\n",
    "    rf_y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rf_auc = roc_auc_score(y_test, rf_y_pred_proba)\n",
    "    rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "    rf_precision = precision_score(y_test, rf_y_pred, zero_division=0)\n",
    "    rf_recall = recall_score(y_test, rf_y_pred, zero_division=0)\n",
    "    rf_f1 = f1_score(y_test, rf_y_pred, zero_division=0)\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    results_fixed[dataset_name] = {\n",
    "        'AUC': rf_auc,\n",
    "        'Accuracy': rf_accuracy,\n",
    "        'Precision': rf_precision,\n",
    "        'Recall': rf_recall,\n",
    "        'F1': rf_f1,\n",
    "        'Top Features': feature_importance.head(5)['feature'].tolist(),\n",
    "        'Feature Importances': feature_importance.head(10),\n",
    "        'Sample Size': len(X),\n",
    "        'Conversion Rate': y.mean()\n",
    "    }\n",
    "    \n",
    "    # ============ LOG METRICS TO WANDB ============\n",
    "    wandb.log({\n",
    "        f\"{dataset_name}/auc\": rf_auc,\n",
    "        f\"{dataset_name}/accuracy\": rf_accuracy,\n",
    "        f\"{dataset_name}/precision\": rf_precision,\n",
    "        f\"{dataset_name}/recall\": rf_recall,\n",
    "        f\"{dataset_name}/f1\": rf_f1,\n",
    "        f\"{dataset_name}/train_size\": len(X_train),\n",
    "        f\"{dataset_name}/test_size\": len(X_test)\n",
    "    })\n",
    "    \n",
    "    # ============ LOG VISUALIZATIONS TO WANDB ============\n",
    "    # ROC Curve\n",
    "    try:\n",
    "        roc_fig = plot_roc(y_test, rf_y_pred_proba, labels=['No Convert', 'Convert'])\n",
    "        wandb.log({f\"{dataset_name}/roc_curve\": roc_fig})\n",
    "    except:\n",
    "        print(f\"  Note: Could not plot ROC for {dataset_name}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    try:\n",
    "        cm_fig = plot_confusion_matrix(y_test, rf_y_pred, labels=['No Convert', 'Convert'])\n",
    "        wandb.log({f\"{dataset_name}/confusion_matrix\": cm_fig})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Feature Importance Plot\n",
    "    try:\n",
    "        if len(feature_importance) > 0:\n",
    "            # Create feature importance table for wandb\n",
    "            importance_table = wandb.Table(dataframe=feature_importance.head(20))\n",
    "            wandb.log({f\"{dataset_name}/feature_importance\": importance_table})\n",
    "            \n",
    "            # Log top features as summary\n",
    "            wandb.run.summary[f\"{dataset_name}_top_feature\"] = feature_importance.iloc[0]['feature']\n",
    "            wandb.run.summary[f\"{dataset_name}_top_importance\"] = feature_importance.iloc[0]['importance']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Store for comparison\n",
    "    run_metrics.append({\n",
    "        'dataset': dataset_name,\n",
    "        'auc': rf_auc,\n",
    "        'accuracy': rf_accuracy,\n",
    "        'f1': rf_f1\n",
    "    })\n",
    "    \n",
    "    print(f\"  ‚úì Fixed Random Forest AUC: {rf_auc:.3f}\")\n",
    "    print(f\"  ‚úì Top 3 features: {feature_importance.head(3)['feature'].tolist()}\")\n",
    "\n",
    "# ============ CREATE COMPARISON VISUALIZATION ============\n",
    "print(\"\\nüìä Creating model comparison dashboard...\")\n",
    "\n",
    "# Create comparison table for wandb\n",
    "comparison_data = []\n",
    "for dataset_name, result in results_fixed.items():\n",
    "    comparison_data.append([\n",
    "        dataset_name,\n",
    "        result['Sample Size'],\n",
    "        result['Conversion Rate'],\n",
    "        result['AUC'],\n",
    "        result['Accuracy'],\n",
    "        result['F1'],\n",
    "        result['Top Features'][0] if result['Top Features'] else 'N/A'\n",
    "    ])\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data, \n",
    "    columns=['Dataset', 'Samples', 'Conv_Rate', 'AUC', 'Accuracy', 'F1', 'Top_Feature'])\n",
    "\n",
    "# Log comparison table\n",
    "comparison_table = wandb.Table(dataframe=comparison_df)\n",
    "wandb.log({\"model_comparison\": comparison_table})\n",
    "\n",
    "# Log comparison chart data\n",
    "wandb.log({\n",
    "    \"comparison/auc_by_dataset\": wandb.plot.bar(\n",
    "        comparison_table, \"Dataset\", \"AUC\",\n",
    "        title=\"AUC by Dataset\"\n",
    "    ),\n",
    "    \"comparison/f1_by_dataset\": wandb.plot.bar(\n",
    "        comparison_table, \"Dataset\", \"F1\",\n",
    "        title=\"F1 Score by Dataset\"\n",
    "    )\n",
    "})\n",
    "\n",
    "# Performance Comparison After Fix\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REALISTIC PERFORMANCE COMPARISON (NO LEAKAGE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_fixed = []\n",
    "for dataset_name, result in results_fixed.items():\n",
    "    comparison_fixed.append({\n",
    "        'Aggregation Strategy': dataset_name,\n",
    "        'Samples': f\"{result['Sample Size']:,}\",\n",
    "        'Conv Rate': f\"{result['Conversion Rate']:.1%}\",\n",
    "        'Realistic AUC': f\"{result['AUC']:.3f}\",\n",
    "        'Accuracy': f\"{result['Accuracy']:.3f}\",\n",
    "        'F1 Score': f\"{result['F1']:.3f}\",\n",
    "        'Top Feature': result['Top Features'][0] if result['Top Features'] else 'N/A'\n",
    "    })\n",
    "\n",
    "comparison_fixed_df = pd.DataFrame(comparison_fixed)\n",
    "comparison_fixed_df = comparison_fixed_df.sort_values('Realistic AUC', ascending=False)\n",
    "\n",
    "print(\"\\nüìà REALISTIC PERFORMANCE RANKING:\")\n",
    "for i, row in comparison_fixed_df.iterrows():\n",
    "    print(f\"{i+1}. {row['Aggregation Strategy']}:\")\n",
    "    print(f\"   Conversion Rate: {row['Conv Rate']}\")\n",
    "    print(f\"   Realistic AUC: {row['Realistic AUC']}\")\n",
    "    print(f\"   Accuracy: {row['Accuracy']}\")\n",
    "    print(f\"   F1 Score: {row['F1 Score']}\")\n",
    "    print(f\"   Top Feature: {row['Top Feature']}\")\n",
    "    print()\n",
    "\n",
    "# Find best realistic strategy\n",
    "best_realistic_strategy = comparison_fixed_df.iloc[0]['Aggregation Strategy']\n",
    "best_realistic_auc = float(comparison_fixed_df.iloc[0]['Realistic AUC'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUSINESS INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüèÜ REAL BEST STRATEGY: {best_realistic_strategy}\")\n",
    "print(f\"   Realistic AUC: {best_realistic_auc:.3f}\")\n",
    "\n",
    "print(f\"\\nüîç REAL TOP CONVERSION DRIVERS:\")\n",
    "if best_realistic_strategy in results_fixed:\n",
    "    top_features = results_fixed[best_realistic_strategy]['Top Features']\n",
    "    for i, feature in enumerate(top_features[:5], 1):\n",
    "        print(f\"   {i}. {feature}\")\n",
    "\n",
    "# ============ SAVE BEST MODEL AND LOG TO WANDB ============\n",
    "if best_realistic_strategy in datasets_fixed:\n",
    "    X, y = datasets_fixed[best_realistic_strategy]\n",
    "    \n",
    "    # Train final model on full data\n",
    "    final_model = RandomForestClassifier(\n",
    "        n_estimators=config.n_estimators,\n",
    "        max_depth=config.max_depth,\n",
    "        min_samples_split=config.min_samples_split,\n",
    "        class_weight=config.class_weight,\n",
    "        random_state=config.random_state\n",
    "    )\n",
    "    final_model.fit(X, y)\n",
    "    \n",
    "    # Save model locally\n",
    "    model_data = {\n",
    "        'model': final_model,\n",
    "        'feature_names': X.columns.tolist(),\n",
    "        'aggregation_strategy': best_realistic_strategy,\n",
    "        'realistic_auc': best_realistic_auc,\n",
    "        'config': dict(config)\n",
    "    }\n",
    "    \n",
    "    model_filename = 'realistic_conversion_model.pkl'\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(model_data, f)\n",
    "    \n",
    "    print(f\"\\nüíæ Saving best model...\")\n",
    "    print(f\"‚úì Model saved: {model_filename}\")\n",
    "    print(f\"‚úì Strategy: {best_realistic_strategy}\")\n",
    "    print(f\"‚úì Realistic AUC: {best_realistic_auc:.3f}\")\n",
    "    print(f\"‚úì Features used: {len(X.columns)}\")\n",
    "    \n",
    "    # ============ LOG MODEL AS ARTIFACT ============\n",
    "    print(\"\\nüì§ Logging model to wandb...\")\n",
    "    \n",
    "    # Create wandb artifact\n",
    "    artifact = wandb.Artifact(\n",
    "        name=f\"conversion-model-{best_realistic_strategy.lower().replace(' ', '-')}\",\n",
    "        type=\"model\",\n",
    "        description=f\"Random Forest model for {best_realistic_strategy} with AUC {best_realistic_auc:.3f}\",\n",
    "        metadata={\n",
    "            \"strategy\": best_realistic_strategy,\n",
    "            \"auc\": best_realistic_auc,\n",
    "            \"n_features\": len(X.columns),\n",
    "            \"n_samples\": len(X),\n",
    "            \"conversion_rate\": y.mean()\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add model file\n",
    "    artifact.add_file(model_filename)\n",
    "    \n",
    "    # Add feature importance CSV\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': final_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    feature_importance_filename = 'feature_importance.csv'\n",
    "    feature_importance_df.to_csv(feature_importance_filename, index=False)\n",
    "    artifact.add_file(feature_importance_filename)\n",
    "    \n",
    "    # Log artifact\n",
    "    wandb.log_artifact(artifact)\n",
    "    \n",
    "    print(f\"‚úì Model logged to wandb as artifact\")\n",
    "    print(f\"‚úì Feature importance saved: {feature_importance_filename}\")\n",
    "\n",
    "# ============ LOG FINAL SUMMARY METRICS ============\n",
    "wandb.run.summary[\"best_strategy\"] = best_realistic_strategy\n",
    "wandb.run.summary[\"best_auc\"] = best_realistic_auc\n",
    "wandb.run.summary[\"n_datasets_evaluated\"] = len(datasets_fixed)\n",
    "wandb.run.summary[\"total_samples\"] = sum([len(X) for X, _ in datasets_fixed.values()])\n",
    "\n",
    "# ============ FINISH WANDB RUN ============\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WANDB TRACKING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Run complete! View results at: {wandb.run.get_url()}\")\n",
    "print(f\"üìä Project: france-hvac\")\n",
    "print(f\"üè∑Ô∏è  Run name: credit-policy-realistic-models\")\n",
    "\n",
    "wandb.finish()\n",
    "print(\"‚úì Wandb run finished successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6529ee-6010-4190-845e-187b9c8843f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[Poetry] ai-france-hvac",
   "language": "python",
   "name": "ai-france-hvac-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
