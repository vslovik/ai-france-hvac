{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6abfb71b-7009-444e-b77b-75d07abc7c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive customer removal analysis...\n",
      "====================================================================================================\n",
      "COMPREHENSIVE CUSTOMER REMOVAL ANALYSIS\n",
      "====================================================================================================\n",
      "Previous dataset: 38,697 quotes from 25,940 customers\n",
      "New dataset: 34,275 quotes from 23,898 customers\n",
      "Customers removed: 2,042\n",
      "Quotes removed: 4,422\n",
      "\n",
      "1. CUSTOMER CHANGES:\n",
      "   Removed customers: 3,031\n",
      "   Added customers: 989\n",
      "   Common customers: 22,909\n",
      "\n",
      "==================================================\n",
      "ANALYSIS 1: BASIC CUSTOMER CHARACTERISTICS\n",
      "==================================================\n",
      "\n",
      "REMOVED CUSTOMERS:\n",
      "  • Customers: 3,031\n",
      "  • Avg quotes per customer: 1.18\n",
      "  • Conversion rate: 45.20%\n",
      "  • Avg quote price: €3,607\n",
      "  • Avg tenure (days): 14\n",
      "  • Single-quote customers: 85.7%\n",
      "\n",
      "RETAINED CUSTOMERS:\n",
      "  • Customers: 22,909\n",
      "  • Avg quotes per customer: 1.53\n",
      "  • Conversion rate: 40.63%\n",
      "  • Avg quote price: €7,070\n",
      "  • Avg tenure (days): 23\n",
      "  • Single-quote customers: 65.5%\n",
      "\n",
      "NEWLY ADDED CUSTOMERS:\n",
      "  • Customers: 989\n",
      "  • Avg quotes per customer: 1.30\n",
      "  • Conversion rate: 21.33%\n",
      "  • Avg quote price: €6,567\n",
      "  • Avg tenure (days): 0\n",
      "  • Single-quote customers: 75.5%\n",
      "\n",
      "==================================================\n",
      "ANALYSIS 2: TEMPORAL PATTERNS\n",
      "==================================================\n",
      "\n",
      "Removed customers - Temporal patterns:\n",
      "  • First quote date: 2023-01-02\n",
      "  • Last quote date: 2025-12-14\n",
      "  • Peak month: 2025-10\n",
      "  • Quotes in last 6 months: 74.8%\n",
      "\n",
      "Retained customers - Temporal patterns:\n",
      "  • First quote date: 2023-01-02\n",
      "  • Last quote date: 2025-12-14\n",
      "  • Peak month: 2025-10\n",
      "  • Quotes in last 6 months: 67.5%\n",
      "\n",
      "Added customers - Temporal patterns:\n",
      "  • First quote date: 2025-11-12\n",
      "  • Last quote date: 2026-01-22\n",
      "  • Peak month: 2026-01\n",
      "  • Quotes in last 6 months: 100.0%\n",
      "\n",
      "==================================================\n",
      "ANALYSIS 3: PRODUCT & COMMERCIAL CHARACTERISTICS\n",
      "==================================================\n",
      "\n",
      "Removed customers:\n",
      "  Top 3 equipment types:\n",
      "    • Chaudière: 31.4%\n",
      "    • Pompe à chaleur: 15.7%\n",
      "    • Plomberie Sanitaire: 14.8%\n",
      "\n",
      "Retained customers:\n",
      "  Top 3 equipment types:\n",
      "    • Chaudière: 28.8%\n",
      "    • Poêle: 20.9%\n",
      "    • Pompe à chaleur: 19.1%\n",
      "\n",
      "Added customers:\n",
      "  Top 3 equipment types:\n",
      "    • BOILER_GAS: 38.5%\n",
      "    • STOVE: 22.1%\n",
      "    • HEAT_PUMP: 15.3%\n",
      "  Top 3 brands:\n",
      "    • ATLANTIC: 16.9%\n",
      "    • MITSUBISHI ELECTRIC: 14.9%\n",
      "    • SAUNIER DUVAL: 11.7%\n",
      "  Top 3 commercial functions:\n",
      "    • Commercial: 69.9%\n",
      "    • Technico-Commercial: 6.6%\n",
      "    • Contre maître: 4.1%\n",
      "\n",
      "==================================================\n",
      "ANALYSIS 4: CONVERSION BEHAVIOR ANALYSIS\n",
      "==================================================\n",
      "\n",
      "Removed customers:\n",
      "  • First quote conversion rate: 41.50%\n",
      "  • Avg days to convert: 6 days\n",
      "\n",
      "Retained customers:\n",
      "  • First quote conversion rate: 32.07%\n",
      "  • Avg days to convert: 17 days\n",
      "\n",
      "Added customers:\n",
      "  • First quote conversion rate: 18.10%\n",
      "  • Avg days to convert: 0 days\n",
      "\n",
      "==================================================\n",
      "ANALYSIS 5: NEW DATASET FEATURES COMPARISON\n",
      "==================================================\n",
      "New features available in v3: ['statut_client', 'marque_produit', 'regroup_famille_equipement_produit', 'fonction_commercial', 'fg_nouveau_process_relance_devis', 'dt_prem_devis']\n",
      "\n",
      "==================================================\n",
      "ANALYSIS 6: PREDICTIVE POWER OF REMOVED VS RETAINED\n",
      "==================================================\n",
      "\n",
      "FEATURE COMPARISON (Mean values):\n",
      "\n",
      "Feature                | Removed | Retained | Difference\n",
      "-------------------------------------------------------\n",
      "total_quotes         |    1.18 |     1.53 | -0.348\n",
      "converted            |    0.45 |     0.41 | +0.046\n",
      "avg_price            | 3607.38 |  7070.15 | -3462.773\n",
      "engagement_density   |    0.95 |     1.04 | -0.089\n",
      "\n",
      "==================================================\n",
      "ANALYSIS 7: BUSINESS IMPACT OF CUSTOMER REMOVAL\n",
      "==================================================\n",
      "\n",
      "POTENTIAL BUSINESS IMPACT:\n",
      "• Customers removed: 3,031\n",
      "• Avg quote value: €3,996\n",
      "• Conversion rate: 41.0%\n",
      "• Estimated lost revenue opportunity: €4,969,941\n",
      "\n",
      "COMPARISON WITH RETAINED CUSTOMERS:\n",
      "• Quote value difference: €-3,338\n",
      "• Conversion rate difference: +11.1%\n",
      "\n",
      "==================================================\n",
      "ANALYSIS 8: DIAGNOSTIC RECOMMENDATIONS\n",
      "==================================================\n",
      "\n",
      "RECOMMENDATIONS BASED ON ANALYSIS:\n",
      "1. ⚠️ WARNING: REMOVED CUSTOMERS WERE HIGH-CONVERTERS\n",
      "2. → This explains the accuracy drop\n",
      "3. → Need to investigate WHY high-converters were removed\n",
      "\n",
      "==================================================\n",
      "SAVING DETAILED ANALYSIS\n",
      "==================================================\n",
      "✓ Detailed analysis saved to: data/customer_removal_analysis.csv\n",
      "\n",
      "====================================================================================================\n",
      "ADDITIONAL TARGETED ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "SINGLE-QUOTE CUSTOMER ANALYSIS:\n",
      "• Removed customers: 85.7% had only one quote\n",
      "• Retained customers: 65.5% had only one quote\n",
      "→ REMOVAL BIAS: Single-quote customers disproportionately removed\n",
      "\n",
      "TOP AGENCIES ANALYSIS:\n",
      "Removed customers - Top 3 agencies:\n",
      "  • VB Gaz: 13.8%\n",
      "  • Aujard: 13.6%\n",
      "  • Chauffage du Nord: 8.2%\n",
      "\n",
      "Retained customers - Top 3 agencies:\n",
      "  • VB Gaz: 12.5%\n",
      "  • Agence Caen: 11.5%\n",
      "  • Chauffage du Nord: 9.2%\n",
      "\n",
      "TIME-BASED ANALYSIS:\n",
      "Removed customers - Quote date range:\n",
      "  • Earliest: 2023-01-02\n",
      "  • Latest: 2025-12-14\n",
      "\n",
      "Retained customers - Quote date range:\n",
      "  • Earliest: 2023-01-02\n",
      "  • Latest: 2025-12-14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "def diagnose_removed_customers(prev_file, new_file):\n",
    "    \"\"\"\n",
    "    Comprehensive diagnosis of what changed between dataset versions\n",
    "    \"\"\"\n",
    "    print(\"=\" * 100)\n",
    "    print(\"COMPREHENSIVE CUSTOMER REMOVAL ANALYSIS\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Load both datasets\n",
    "    df_prev = pd.read_csv(prev_file)\n",
    "    df_new = pd.read_csv(new_file)\n",
    "    \n",
    "    # Ensure we have the key columns\n",
    "    df_prev['dt_creation_devis'] = pd.to_datetime(df_prev['dt_creation_devis'])\n",
    "    df_new['dt_creation_devis'] = pd.to_datetime(df_new['dt_creation_devis'])\n",
    "    \n",
    "    print(f\"Previous dataset: {len(df_prev):,} quotes from {df_prev['numero_compte'].nunique():,} customers\")\n",
    "    print(f\"New dataset: {len(df_new):,} quotes from {df_new['numero_compte'].nunique():,} customers\")\n",
    "    print(f\"Customers removed: {df_prev['numero_compte'].nunique() - df_new['numero_compte'].nunique():,}\")\n",
    "    print(f\"Quotes removed: {len(df_prev) - len(df_new):,}\")\n",
    "    \n",
    "    # Identify removed and added customers\n",
    "    prev_customers = set(df_prev['numero_compte'].unique())\n",
    "    new_customers = set(df_new['numero_compte'].unique())\n",
    "    \n",
    "    removed_customers = prev_customers - new_customers\n",
    "    added_customers = new_customers - prev_customers\n",
    "    \n",
    "    print(f\"\\n1. CUSTOMER CHANGES:\")\n",
    "    print(f\"   Removed customers: {len(removed_customers):,}\")\n",
    "    print(f\"   Added customers: {len(added_customers):,}\")\n",
    "    print(f\"   Common customers: {len(prev_customers & new_customers):,}\")\n",
    "    \n",
    "    # Get data for removed customers\n",
    "    df_removed = df_prev[df_prev['numero_compte'].isin(removed_customers)].copy()\n",
    "    df_kept = df_prev[df_prev['numero_compte'].isin(prev_customers & new_customers)].copy()\n",
    "    df_added = df_new[df_new['numero_compte'].isin(added_customers)].copy()\n",
    "    \n",
    "    # ANALYSIS 1: BASIC CHARACTERISTICS\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ANALYSIS 1: BASIC CUSTOMER CHARACTERISTICS\")\n",
    "    print('='*50)\n",
    "    \n",
    "    def analyze_customer_group(df, group_name):\n",
    "        \"\"\"Analyze a group of customers\"\"\"\n",
    "        if len(df) == 0:\n",
    "            print(f\"\\n{group_name}: No data\")\n",
    "            return {}\n",
    "        \n",
    "        # Customer-level stats\n",
    "        customer_stats = df.groupby('numero_compte').agg({\n",
    "            'numero_compte': 'count',\n",
    "            'fg_devis_accepte': 'max',\n",
    "            'mt_apres_remise_ht_devis': 'mean',\n",
    "            'dt_creation_devis': ['min', 'max']\n",
    "        }).reset_index()\n",
    "        \n",
    "        customer_stats.columns = ['numero_compte', 'total_quotes', 'converted', \n",
    "                                  'avg_price', 'first_quote_date', 'last_quote_date']\n",
    "        \n",
    "        # Calculate tenure\n",
    "        customer_stats['tenure_days'] = (customer_stats['last_quote_date'] - \n",
    "                                        customer_stats['first_quote_date']).dt.days\n",
    "        \n",
    "        stats = {\n",
    "            'count': len(customer_stats),\n",
    "            'avg_quotes': customer_stats['total_quotes'].mean(),\n",
    "            'conversion_rate': customer_stats['converted'].mean(),\n",
    "            'avg_price': customer_stats['avg_price'].mean(),\n",
    "            'avg_tenure': customer_stats['tenure_days'].mean(),\n",
    "            'single_quote_pct': (customer_stats['total_quotes'] == 1).mean() * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{group_name}:\")\n",
    "        print(f\"  • Customers: {stats['count']:,}\")\n",
    "        print(f\"  • Avg quotes per customer: {stats['avg_quotes']:.2f}\")\n",
    "        print(f\"  • Conversion rate: {stats['conversion_rate']:.2%}\")\n",
    "        print(f\"  • Avg quote price: €{stats['avg_price']:,.0f}\")\n",
    "        print(f\"  • Avg tenure (days): {stats['avg_tenure']:.0f}\")\n",
    "        print(f\"  • Single-quote customers: {stats['single_quote_pct']:.1f}%\")\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    # Analyze all groups\n",
    "    removed_stats = analyze_customer_group(df_removed, \"REMOVED CUSTOMERS\")\n",
    "    kept_stats = analyze_customer_group(df_kept, \"RETAINED CUSTOMERS\")\n",
    "    added_stats = analyze_customer_group(df_added, \"NEWLY ADDED CUSTOMERS\")\n",
    "    \n",
    "    # ANALYSIS 2: TEMPORAL PATTERNS\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ANALYSIS 2: TEMPORAL PATTERNS\")\n",
    "    print('='*50)\n",
    "    \n",
    "    def analyze_temporal_patterns(df, group_name):\n",
    "        \"\"\"Analyze when these customers were active\"\"\"\n",
    "        if len(df) == 0:\n",
    "            return\n",
    "        \n",
    "        df['quote_year_month'] = df['dt_creation_devis'].dt.to_period('M')\n",
    "        monthly_counts = df.groupby('quote_year_month').agg({\n",
    "            'numero_compte': 'nunique',\n",
    "            'fg_devis_accepte': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        monthly_counts.columns = ['period', 'unique_customers', 'conversion_rate']\n",
    "        \n",
    "        print(f\"\\n{group_name} - Temporal patterns:\")\n",
    "        print(f\"  • First quote date: {df['dt_creation_devis'].min().date()}\")\n",
    "        print(f\"  • Last quote date: {df['dt_creation_devis'].max().date()}\")\n",
    "        print(f\"  • Peak month: {monthly_counts.loc[monthly_counts['unique_customers'].idxmax(), 'period']}\")\n",
    "        \n",
    "        # Recent vs historical\n",
    "        cutoff_date = pd.Timestamp('2024-06-01')  # Adjust based on your data\n",
    "        recent_mask = df['dt_creation_devis'] >= cutoff_date\n",
    "        \n",
    "        if recent_mask.any():\n",
    "            recent_pct = recent_mask.mean() * 100\n",
    "            print(f\"  • Quotes in last 6 months: {recent_pct:.1f}%\")\n",
    "    \n",
    "    analyze_temporal_patterns(df_removed, \"Removed customers\")\n",
    "    analyze_temporal_patterns(df_kept, \"Retained customers\")\n",
    "    analyze_temporal_patterns(df_added, \"Added customers\")\n",
    "    \n",
    "    # ANALYSIS 3: PRODUCT & COMMERCIAL PATTERNS\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ANALYSIS 3: PRODUCT & COMMERCIAL CHARACTERISTICS\")\n",
    "    print('='*50)\n",
    "    \n",
    "    def analyze_product_commercial(df, group_name):\n",
    "        \"\"\"Analyze what products and commercial patterns\"\"\"\n",
    "        if len(df) == 0:\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n{group_name}:\")\n",
    "        \n",
    "        # Product family (use new column if available, otherwise old)\n",
    "        product_col = 'regroup_famille_equipement_produit' if 'regroup_famille_equipement_produit' in df.columns else 'famille_equipement_produit'\n",
    "        if product_col in df.columns:\n",
    "            top_products = df[product_col].value_counts().head(3)\n",
    "            print(f\"  Top 3 equipment types:\")\n",
    "            for product, count in top_products.items():\n",
    "                pct = count / len(df) * 100\n",
    "                print(f\"    • {product}: {pct:.1f}%\")\n",
    "        \n",
    "        # Brands if available\n",
    "        if 'marque_produit' in df.columns:\n",
    "            top_brands = df['marque_produit'].value_counts().head(3)\n",
    "            print(f\"  Top 3 brands:\")\n",
    "            for brand, count in top_brands.items():\n",
    "                pct = count / len(df) * 100\n",
    "                print(f\"    • {brand}: {pct:.1f}%\")\n",
    "        \n",
    "        # Commercial function if available\n",
    "        if 'fonction_commercial' in df.columns:\n",
    "            top_funcs = df['fonction_commercial'].value_counts().head(3)\n",
    "            print(f\"  Top 3 commercial functions:\")\n",
    "            for func, count in top_funcs.items():\n",
    "                pct = count / len(df) * 100\n",
    "                print(f\"    • {func}: {pct:.1f}%\")\n",
    "    \n",
    "    analyze_product_commercial(df_removed, \"Removed customers\")\n",
    "    analyze_product_commercial(df_kept, \"Retained customers\")\n",
    "    analyze_product_commercial(df_added, \"Added customers\")\n",
    "    \n",
    "    # ANALYSIS 4: CONVERSION PATTERNS\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ANALYSIS 4: CONVERSION BEHAVIOR ANALYSIS\")\n",
    "    print('='*50)\n",
    "    \n",
    "    def analyze_conversion_patterns(df, group_name):\n",
    "        \"\"\"Analyze how conversion happens in this group\"\"\"\n",
    "        if len(df) == 0:\n",
    "            return\n",
    "        \n",
    "        # Conversion by quote position\n",
    "        df = df.sort_values(['numero_compte', 'dt_creation_devis']).copy()\n",
    "        df['quote_rank'] = df.groupby('numero_compte').cumcount() + 1\n",
    "        \n",
    "        # What quote position converts?\n",
    "        conversion_by_position = df.groupby('quote_rank')['fg_devis_accepte'].agg(['mean', 'count']).reset_index()\n",
    "        conversion_by_position.columns = ['quote_position', 'conversion_rate', 'count']\n",
    "        \n",
    "        first_quote_conversion = conversion_by_position[conversion_by_position['quote_position'] == 1]['conversion_rate'].values\n",
    "        if len(first_quote_conversion) > 0:\n",
    "            print(f\"\\n{group_name}:\")\n",
    "            print(f\"  • First quote conversion rate: {first_quote_conversion[0]:.2%}\")\n",
    "        \n",
    "        # Time to conversion for converters\n",
    "        converters = df[df['fg_devis_accepte'] == 1]\n",
    "        if len(converters) > 0:\n",
    "            # Get first conversion date for each customer\n",
    "            first_conversion = converters.groupby('numero_compte')['dt_creation_devis'].min().reset_index()\n",
    "            first_conversion.columns = ['numero_compte', 'first_conversion_date']\n",
    "            \n",
    "            # Merge with first quote date\n",
    "            first_quote = df.groupby('numero_compte')['dt_creation_devis'].min().reset_index()\n",
    "            first_quote.columns = ['numero_compte', 'first_quote_date']\n",
    "            \n",
    "            conversion_timing = pd.merge(first_conversion, first_quote, on='numero_compte')\n",
    "            conversion_timing['days_to_convert'] = (conversion_timing['first_conversion_date'] - \n",
    "                                                   conversion_timing['first_quote_date']).dt.days\n",
    "            \n",
    "            if len(conversion_timing) > 0:\n",
    "                print(f\"  • Avg days to convert: {conversion_timing['days_to_convert'].mean():.0f} days\")\n",
    "    \n",
    "    analyze_conversion_patterns(df_removed, \"Removed customers\")\n",
    "    analyze_conversion_patterns(df_kept, \"Retained customers\")\n",
    "    analyze_conversion_patterns(df_added, \"Added customers\")\n",
    "    \n",
    "    # ANALYSIS 5: NEW FEATURES ANALYSIS (Critical for new dataset)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ANALYSIS 5: NEW DATASET FEATURES COMPARISON\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Check which new features are available\n",
    "    new_features = ['statut_client', 'marque_produit', 'regroup_famille_equipement_produit',\n",
    "                    'fonction_commercial', 'fg_nouveau_process_relance_devis', 'dt_prem_devis']\n",
    "    \n",
    "    available_features = [f for f in new_features if f in df_new.columns]\n",
    "    print(f\"New features available in v3: {available_features}\")\n",
    "    \n",
    "    # Compare feature distributions between removed and kept customers\n",
    "    if 'statut_client' in df_removed.columns:\n",
    "        print(f\"\\nCLIENT STATUS DISTRIBUTION:\")\n",
    "        \n",
    "        for group_name, group_df in [(\"Removed\", df_removed), (\"Retained\", df_kept), (\"Added\", df_added)]:\n",
    "            if len(group_df) > 0 and 'statut_client' in group_df.columns:\n",
    "                status_dist = group_df['statut_client'].value_counts(normalize=True)\n",
    "                print(f\"\\n{group_name} customers:\")\n",
    "                for status, pct in status_dist.items():\n",
    "                    print(f\"  • {status}: {pct:.1%}\")\n",
    "    \n",
    "    if 'fg_nouveau_process_relance_devis' in df_removed.columns:\n",
    "        print(f\"\\nNEW PROCESS ADOPTION:\")\n",
    "        \n",
    "        for group_name, group_df in [(\"Removed\", df_removed), (\"Retained\", df_kept), (\"Added\", df_added)]:\n",
    "            if len(group_df) > 0 and 'fg_nouveau_process_relance_devis' in group_df.columns:\n",
    "                process_usage = group_df['fg_nouveau_process_relance_devis'].mean()\n",
    "                print(f\"  {group_name}: {process_usage:.1%} use new process\")\n",
    "    \n",
    "    # ANALYSIS 6: PREDICTIVE POWER ANALYSIS\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ANALYSIS 6: PREDICTIVE POWER OF REMOVED VS RETAINED\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create simple features to see predictive patterns\n",
    "    def create_diagnostic_features(df):\n",
    "        \"\"\"Create features to understand predictive patterns\"\"\"\n",
    "        if len(df) == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        for customer_id, customer_data in df.groupby('numero_compte'):\n",
    "            f = {'customer_id': customer_id}\n",
    "            \n",
    "            # Basic features\n",
    "            f['total_quotes'] = len(customer_data)\n",
    "            f['converted'] = customer_data['fg_devis_accepte'].max()\n",
    "            f['avg_price'] = customer_data['mt_apres_remise_ht_devis'].mean()\n",
    "            \n",
    "            # Temporal\n",
    "            if len(customer_data) > 1:\n",
    "                time_span = (customer_data['dt_creation_devis'].max() - \n",
    "                            customer_data['dt_creation_devis'].min()).days + 1\n",
    "                f['engagement_density'] = len(customer_data) / time_span\n",
    "            else:\n",
    "                f['engagement_density'] = 1\n",
    "            \n",
    "            # Product variety\n",
    "            product_col = 'regroup_famille_equipement_produit' if 'regroup_famille_equipement_produit' in customer_data.columns else 'famille_equipement_produit'\n",
    "            if product_col in customer_data.columns:\n",
    "                f['product_variety'] = customer_data[product_col].nunique()\n",
    "            \n",
    "            features.append(f)\n",
    "        \n",
    "        return pd.DataFrame(features)\n",
    "    \n",
    "    # Create features for each group\n",
    "    removed_features = create_diagnostic_features(df_removed)\n",
    "    kept_features = create_diagnostic_features(df_kept)\n",
    "    \n",
    "    if len(removed_features) > 0 and len(kept_features) > 0:\n",
    "        print(\"\\nFEATURE COMPARISON (Mean values):\")\n",
    "        print(\"\\nFeature                | Removed | Retained | Difference\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        for feature in ['total_quotes', 'converted', 'avg_price', 'engagement_density']:\n",
    "            if feature in removed_features.columns and feature in kept_features.columns:\n",
    "                removed_mean = removed_features[feature].mean()\n",
    "                kept_mean = kept_features[feature].mean()\n",
    "                diff = removed_mean - kept_mean\n",
    "                print(f\"{feature:20} | {removed_mean:7.2f} | {kept_mean:8.2f} | {diff:+.3f}\")\n",
    "    \n",
    "    # ANALYSIS 7: BUSINESS IMPACT ANALYSIS\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ANALYSIS 7: BUSINESS IMPACT OF CUSTOMER REMOVAL\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Estimate business impact\n",
    "    if len(df_removed) > 0:\n",
    "        # Potential lost revenue\n",
    "        avg_quote_value = df_removed['mt_apres_remise_ht_devis'].mean()\n",
    "        conversion_rate = df_removed['fg_devis_accepte'].mean()\n",
    "        potential_customers = len(removed_customers)\n",
    "        \n",
    "        print(f\"\\nPOTENTIAL BUSINESS IMPACT:\")\n",
    "        print(f\"• Customers removed: {potential_customers:,}\")\n",
    "        print(f\"• Avg quote value: €{avg_quote_value:,.0f}\")\n",
    "        print(f\"• Conversion rate: {conversion_rate:.1%}\")\n",
    "        print(f\"• Estimated lost revenue opportunity: €{potential_customers * avg_quote_value * conversion_rate:,.0f}\")\n",
    "        \n",
    "        # Compare with retained\n",
    "        avg_quote_kept = df_kept['mt_apres_remise_ht_devis'].mean()\n",
    "        conversion_kept = df_kept['fg_devis_accepte'].mean()\n",
    "        \n",
    "        print(f\"\\nCOMPARISON WITH RETAINED CUSTOMERS:\")\n",
    "        print(f\"• Quote value difference: €{avg_quote_value - avg_quote_kept:+,.0f}\")\n",
    "        print(f\"• Conversion rate difference: {conversion_rate - conversion_kept:+.1%}\")\n",
    "    \n",
    "    # ANALYSIS 8: RECOMMENDATIONS\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"ANALYSIS 8: DIAGNOSTIC RECOMMENDATIONS\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Generate recommendations based on findings\n",
    "    recommendations = []\n",
    "    \n",
    "    # Check if removed customers were systematically different\n",
    "    if len(df_removed) > 0 and len(df_kept) > 0:\n",
    "        # Check conversion rate difference\n",
    "        conv_diff = df_removed['fg_devis_accepte'].mean() - df_kept['fg_devis_accepte'].mean()\n",
    "        \n",
    "        if conv_diff < -0.05:  # Removed customers had much lower conversion\n",
    "            recommendations.append(\"REMOVED CUSTOMERS WERE LOW-CONVERTERS: This is GOOD data cleanup\")\n",
    "            recommendations.append(\"→ Your model should perform BETTER on cleaner data\")\n",
    "            recommendations.append(\"→ Need to adjust expectations: Original model was trained on noisy data\")\n",
    "        \n",
    "        elif conv_diff > 0.05:  # Removed customers had higher conversion\n",
    "            recommendations.append(\"⚠️ WARNING: REMOVED CUSTOMERS WERE HIGH-CONVERTERS\")\n",
    "            recommendations.append(\"→ This explains the accuracy drop\")\n",
    "            recommendations.append(\"→ Need to investigate WHY high-converters were removed\")\n",
    "        \n",
    "        else:\n",
    "            recommendations.append(\"Removed and retained customers have similar conversion rates\")\n",
    "            recommendations.append(\"→ The accuracy drop may be due to OTHER factors\")\n",
    "    \n",
    "    # Check temporal patterns\n",
    "    if len(df_removed) > 0:\n",
    "        removed_end_date = df_removed['dt_creation_devis'].max()\n",
    "        kept_end_date = df_kept['dt_creation_devis'].max()\n",
    "        \n",
    "        if (kept_end_date - removed_end_date).days > 180:\n",
    "            recommendations.append(\"Removed customers were from older time periods\")\n",
    "            recommendations.append(\"→ This is likely intentional data archiving\")\n",
    "            recommendations.append(\"→ Consider adding time-based features to handle recency effects\")\n",
    "    \n",
    "    # Check for systematic patterns in removed customers\n",
    "    if 'statut_client' in df_removed.columns:\n",
    "        status_dist_removed = df_removed['statut_client'].value_counts(normalize=True)\n",
    "        status_dist_kept = df_kept['statut_client'].value_counts(normalize=True)\n",
    "        \n",
    "        # Check if specific status was disproportionately removed\n",
    "        for status in status_dist_removed.index:\n",
    "            removed_pct = status_dist_removed[status]\n",
    "            kept_pct = status_dist_kept.get(status, 0)\n",
    "            \n",
    "            if abs(removed_pct - kept_pct) > 0.1:  # 10% difference\n",
    "                recommendations.append(f\"⚠️ {status} customers disproportionately affected\")\n",
    "                recommendations.append(f\"→ Removed: {removed_pct:.1%}, Kept: {kept_pct:.1%}\")\n",
    "    \n",
    "    # Print recommendations\n",
    "    if recommendations:\n",
    "        print(\"\\nRECOMMENDATIONS BASED ON ANALYSIS:\")\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            print(f\"{i}. {rec}\")\n",
    "    else:\n",
    "        print(\"\\nNo clear patterns detected in removed customers.\")\n",
    "    \n",
    "    # Save detailed analysis to file\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"SAVING DETAILED ANALYSIS\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_data = []\n",
    "    \n",
    "    for group_name, group_df in [(\"Removed\", df_removed), (\"Retained\", df_kept), (\"Added\", df_added)]:\n",
    "        if len(group_df) > 0:\n",
    "            comparison_data.append({\n",
    "                'Group': group_name,\n",
    "                'Customers': group_df['numero_compte'].nunique(),\n",
    "                'Quotes': len(group_df),\n",
    "                'Avg Quotes per Customer': len(group_df) / group_df['numero_compte'].nunique() if group_df['numero_compte'].nunique() > 0 else 0,\n",
    "                'Conversion Rate': group_df['fg_devis_accepte'].mean(),\n",
    "                'Avg Quote Value': group_df['mt_apres_remise_ht_devis'].mean(),\n",
    "                'First Quote Date': group_df['dt_creation_devis'].min().date(),\n",
    "                'Last Quote Date': group_df['dt_creation_devis'].max().date()\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    comparison_df.to_csv('data/customer_removal_analysis.csv', index=False)\n",
    "    print(f\"✓ Detailed analysis saved to: data/customer_removal_analysis.csv\")\n",
    "    \n",
    "    # Return the data for further analysis\n",
    "    return {\n",
    "        'df_removed': df_removed,\n",
    "        'df_kept': df_kept,\n",
    "        'df_added': df_added,\n",
    "        'removed_customers': removed_customers,\n",
    "        'kept_customers': prev_customers & new_customers,\n",
    "        'added_customers': added_customers,\n",
    "        'comparison_df': comparison_df\n",
    "    }\n",
    "\n",
    "\n",
    "prev_file = \"data/data_hes_quotes_france_202512-2.csv\"\n",
    "new_file = \"data/data_hes_quotes_france_202512-3.csv\"\n",
    "\n",
    "print(\"Starting comprehensive customer removal analysis...\")\n",
    "results = diagnose_removed_customers(prev_file, new_file)\n",
    "\n",
    "# Additional targeted analysis based on initial findings\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"ADDITIONAL TARGETED ANALYSIS\")\n",
    "print('='*100)\n",
    "\n",
    "if results['df_removed'] is not None and len(results['df_removed']) > 0:\n",
    "    # Check specific hypotheses\n",
    "    \n",
    "    # Hypothesis 1: Were removed customers mostly single-quote?\n",
    "    removed_customer_quotes = results['df_removed'].groupby('numero_compte').size()\n",
    "    single_quote_removed = (removed_customer_quotes == 1).mean() * 100\n",
    "    \n",
    "    kept_customer_quotes = results['df_kept'].groupby('numero_compte').size()\n",
    "    single_quote_kept = (kept_customer_quotes == 1).mean() * 100\n",
    "    \n",
    "    print(f\"\\nSINGLE-QUOTE CUSTOMER ANALYSIS:\")\n",
    "    print(f\"• Removed customers: {single_quote_removed:.1f}% had only one quote\")\n",
    "    print(f\"• Retained customers: {single_quote_kept:.1f}% had only one quote\")\n",
    "    \n",
    "    if single_quote_removed > single_quote_kept + 10:\n",
    "        print(\"→ REMOVAL BIAS: Single-quote customers disproportionately removed\")\n",
    "    \n",
    "    # Hypothesis 2: Were removed customers from specific agencies/regions?\n",
    "    if 'nom_agence' in results['df_removed'].columns:\n",
    "        top_agencies_removed = results['df_removed']['nom_agence'].value_counts(normalize=True).head(3)\n",
    "        top_agencies_kept = results['df_kept']['nom_agence'].value_counts(normalize=True).head(3)\n",
    "        \n",
    "        print(f\"\\nTOP AGENCIES ANALYSIS:\")\n",
    "        print(\"Removed customers - Top 3 agencies:\")\n",
    "        for agency, pct in top_agencies_removed.items():\n",
    "            print(f\"  • {agency}: {pct:.1%}\")\n",
    "        \n",
    "        print(\"\\nRetained customers - Top 3 agencies:\")\n",
    "        for agency, pct in top_agencies_kept.items():\n",
    "            print(f\"  • {agency}: {pct:.1%}\")\n",
    "    \n",
    "    # Hypothesis 3: Time-based removal?\n",
    "    print(f\"\\nTIME-BASED ANALYSIS:\")\n",
    "    print(f\"Removed customers - Quote date range:\")\n",
    "    print(f\"  • Earliest: {results['df_removed']['dt_creation_devis'].min().date()}\")\n",
    "    print(f\"  • Latest: {results['df_removed']['dt_creation_devis'].max().date()}\")\n",
    "    \n",
    "    print(f\"\\nRetained customers - Quote date range:\")\n",
    "    print(f\"  • Earliest: {results['df_kept']['dt_creation_devis'].min().date()}\")\n",
    "    print(f\"  • Latest: {results['df_kept']['dt_creation_devis'].max().date()}\")\n",
    "    \n",
    "    # Check if removed customers are from older time periods\n",
    "    removed_latest = results['df_removed']['dt_creation_devis'].max()\n",
    "    kept_latest = results['df_kept']['dt_creation_devis'].max()\n",
    "    \n",
    "    if (kept_latest - removed_latest).days > 90:\n",
    "        print(f\"\\n→ TIME BIAS: Removed customers are from older time periods\")\n",
    "        print(f\"  Latest removed quote: {removed_latest.date()}\")\n",
    "        print(f\"  Latest kept quote: {kept_latest.date()}\")\n",
    "        print(f\"  Difference: {(kept_latest - removed_latest).days} days\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[Poetry] ai-france-hvac",
   "language": "python",
   "name": "ai-france-hvac-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
