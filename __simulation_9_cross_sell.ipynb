{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7558d435-7528-437e-bc3f-56bf250766af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ml_features.features import create_features\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "df_quotes = pd.read_csv('cleaned_quote_data.csv')\n",
    "df_quotes['dt_creation_devis'] = pd.to_datetime(df_quotes['dt_creation_devis'])\n",
    "df_quotes['dt_signature_devis'] = pd.to_datetime(df_quotes['dt_signature_devis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd733801-d15b-4b23-b894-0b7a8311e401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 22708 train, 1180 sim customers\n"
     ]
    }
   ],
   "source": [
    "# 1. Customer Split (95%/5%)\n",
    "# --------------------------\n",
    "\n",
    "# First quote per customer\n",
    "cust_first = df_quotes.groupby('numero_compte')['dt_creation_devis'].min().reset_index()\n",
    "cust_first = cust_first.sort_values('dt_creation_devis')\n",
    "\n",
    "# 95th percentile split\n",
    "split_idx = int(len(cust_first) * 0.95)\n",
    "split_date = cust_first.iloc[split_idx]['dt_creation_devis']\n",
    "\n",
    "# Split customers\n",
    "train_cust = cust_first[cust_first['dt_creation_devis'] <= split_date]['numero_compte'].tolist()\n",
    "sim_cust = cust_first[cust_first['dt_creation_devis'] > split_date]['numero_compte'].tolist()\n",
    "\n",
    "# Split data\n",
    "df_train = df_quotes[df_quotes['numero_compte'].isin(train_cust)].copy()\n",
    "df_sim = df_quotes[df_quotes['numero_compte'].isin(sim_cust)].copy()\n",
    "\n",
    "print(f\"Split: {len(train_cust)} train, {len(sim_cust)} sim customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9f68e7-aa82-4361-ab1e-e8b66960a46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REVISING CUSTOMER SPLIT WITH DEBUGGING ===\n",
      "Total unique customers: 23888\n",
      "Split date: 2025-12-08 00:00:00\n",
      "Training customers (first quote <= 2025-12-08 00:00:00): ~22693\n",
      "Simulation customers (first quote > 2025-12-08 00:00:00): ~1195\n",
      "Actual split: 22708 train, 1180 sim customers\n"
     ]
    }
   ],
   "source": [
    "# 1. CUSTOMER SPLIT (95%/5%) - REVISED WITH DEBUGGING\n",
    "print(\"=== REVISING CUSTOMER SPLIT WITH DEBUGGING ===\")\n",
    "\n",
    "# First quote per customer\n",
    "cust_first = df_quotes.groupby('numero_compte')['dt_creation_devis'].min().reset_index()\n",
    "cust_first = cust_first.sort_values('dt_creation_devis')\n",
    "\n",
    "# Check total customers\n",
    "print(f\"Total unique customers: {len(cust_first)}\")\n",
    "\n",
    "# 95th percentile split\n",
    "split_idx = int(len(cust_first) * 0.95)\n",
    "split_date = cust_first.iloc[split_idx]['dt_creation_devis']\n",
    "\n",
    "print(f\"Split date: {split_date}\")\n",
    "print(f\"Training customers (first quote <= {split_date}): ~{split_idx}\")\n",
    "print(f\"Simulation customers (first quote > {split_date}): ~{len(cust_first) - split_idx}\")\n",
    "\n",
    "# Split customers\n",
    "train_cust = cust_first[cust_first['dt_creation_devis'] <= split_date]['numero_compte'].tolist()\n",
    "sim_cust = cust_first[cust_first['dt_creation_devis'] > split_date]['numero_compte'].tolist()\n",
    "\n",
    "print(f\"Actual split: {len(train_cust)} train, {len(sim_cust)} sim customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676d0263-ed63-40a6-a724-92c0c899ede0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INSPECTING SIMULATION CUSTOMERS ===\n",
      "Key columns in df_sim:\n",
      "  prix_total_ht: ‚úó\n",
      "  mt_remise_exceptionnelle_ht: ‚úì\n",
      "  prenom_nom_commercial: ‚úì\n",
      "  famille_equipement_produit: ‚úì\n",
      "\n",
      "Non-converted customers in sim pool: 923/1180\n",
      "\n",
      "Price data check for first 5 non-converted customers:\n",
      "  Customer CL00000840: quotes=2, has_price=False, total_price=‚Ç¨0.00\n",
      "  Customer CL00002004: quotes=1, has_price=False, total_price=‚Ç¨0.00\n",
      "  Customer CL00002625: quotes=1, has_price=False, total_price=‚Ç¨0.00\n",
      "  Customer CL00005945: quotes=2, has_price=False, total_price=‚Ç¨0.00\n",
      "  Customer CL00063542: quotes=1, has_price=False, total_price=‚Ç¨0.00\n"
     ]
    }
   ],
   "source": [
    "# 2. INSPECT SIMULATION CUSTOMERS DATA QUALITY\n",
    "print(\"\\n=== INSPECTING SIMULATION CUSTOMERS ===\")\n",
    "\n",
    "# Create df_sim with all data for simulation customers\n",
    "df_sim = df_quotes[df_quotes['numero_compte'].isin(sim_cust)].copy()\n",
    "\n",
    "# Check key columns existence\n",
    "key_columns = ['prix_total_ht', 'mt_remise_exceptionnelle_ht', 'prenom_nom_commercial', 'famille_equipement_produit']\n",
    "print(\"Key columns in df_sim:\")\n",
    "for col in key_columns:\n",
    "    exists = col in df_sim.columns\n",
    "    print(f\"  {col}: {'‚úì' if exists else '‚úó'}\")\n",
    "\n",
    "# Check non-converted customers\n",
    "sim_conv = df_sim.groupby('numero_compte')['fg_devis_accepte'].max()\n",
    "non_conv_count = (sim_conv == 0).sum()\n",
    "print(f\"\\nNon-converted customers in sim pool: {non_conv_count}/{len(sim_conv)}\")\n",
    "\n",
    "# Check price data for first 5 non-converted customers\n",
    "non_conv_customers = sim_conv[sim_conv == 0].index.tolist()\n",
    "print(\"\\nPrice data check for first 5 non-converted customers:\")\n",
    "for i, cust in enumerate(non_conv_customers[:5]):\n",
    "    cust_data = df_sim[df_sim['numero_compte'] == cust]\n",
    "    has_price = 'prix_total_ht' in cust_data.columns and cust_data['prix_total_ht'].notna().any()\n",
    "    price_sum = cust_data['prix_total_ht'].sum() if has_price else 0\n",
    "    print(f\"  Customer {cust}: quotes={len(cust_data)}, has_price={has_price}, total_price=‚Ç¨{price_sum:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ef77ad-455a-4278-aebd-f3e3a086927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINDING AVAILABLE PRICE COLUMNS ===\n",
      "Found 5 price-related columns:\n",
      "  - mt_apres_remise_ht_devis: sample = 14862.73\n",
      "  - mt_apres_remise_ht_emis_devis: sample = 7431.365\n",
      "  - mt_remise_exceptionnelle_ht: sample = -1500.0\n",
      "  - mt_ttc_apres_aide_devis: sample = 6680.19\n",
      "  - mt_ttc_avant_aide_devis: sample = 15680.19\n",
      "\n",
      "In training data: 5 price columns\n",
      "First 5: ['mt_apres_remise_ht_devis', 'mt_apres_remise_ht_emis_devis', 'mt_remise_exceptionnelle_ht', 'mt_ttc_apres_aide_devis', 'mt_ttc_avant_aide_devis']\n"
     ]
    }
   ],
   "source": [
    "# Find available price/amount columns\n",
    "print(\"=== FINDING AVAILABLE PRICE COLUMNS ===\")\n",
    "\n",
    "price_columns = [col for col in df_sim.columns if any(term in col.lower() for term in ['prix', 'montant', 'cout', 'tarif', 'ht', 'ttc'])]\n",
    "print(f\"Found {len(price_columns)} price-related columns:\")\n",
    "for col in sorted(price_columns):\n",
    "    sample_val = df_sim[col].dropna().iloc[0] if not df_sim[col].dropna().empty else \"N/A\"\n",
    "    print(f\"  - {col}: sample = {sample_val}\")\n",
    "\n",
    "# Also check training data for comparison\n",
    "train_price_cols = [col for col in df_train.columns if any(term in col.lower() for term in ['prix', 'montant', 'cout', 'tarif', 'ht', 'ttc'])]\n",
    "print(f\"\\nIn training data: {len(train_price_cols)} price columns\")\n",
    "print(f\"First 5: {train_price_cols[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093cb3c7-e24b-466f-9b9b-070ae464246d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Create features silently\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m HiddenPrints():\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     X_train_features = \u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Prepare target\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mconverted\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m X_train_features.columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/ai-france-hvac/ml_features/features.py:33\u001b[39m, in \u001b[36mcreate_features\u001b[39m\u001b[34m(df_quotes, dataset_name)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n\u001b[32m     27\u001b[39m feature_funcs = [create_customer_features, create_sequence_features, create_brand_features,\n\u001b[32m     28\u001b[39m                  create_model_features, create_market_features,\n\u001b[32m     29\u001b[39m                  create_equipment_features, create_solution_complexity_features,\n\u001b[32m     30\u001b[39m                  create_timeline_features, create_advanced_timeline_features,\n\u001b[32m     31\u001b[39m                  create_commercial_role_features, create_process_features, create_correction_features]\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m new_df = \u001b[43mfeature_funcs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_quotes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m feature_funcs[\u001b[32m1\u001b[39m:]:\n\u001b[32m     35\u001b[39m     new_df_ = func(df_quotes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/ai-france-hvac/ml_features/customer_features.py:89\u001b[39m, in \u001b[36mcreate_customer_features\u001b[39m\u001b[34m(df, target_type, date_col, customer_col, accept_col, price_col, family_col, agency_col, region_col, discount_col, ttc_col)\u001b[39m\n\u001b[32m     60\u001b[39m agg_dict = {\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# Basic counts\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtotal_quotes\u001b[39m\u001b[33m'\u001b[39m: (customer_col, \u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmain_region\u001b[39m\u001b[33m'\u001b[39m: (region_col, \u001b[38;5;28;01mlambda\u001b[39;00m x: x.mode().iloc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x.mode().empty \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     86\u001b[39m }\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Execute ONE efficient groupby\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m features = \u001b[43mdf_filtered\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomer_col\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43magg_dict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.reset_index()\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# ‚îÄ‚îÄ‚îÄ FAST Derived Features (vectorized) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\u001b[39;00m\n\u001b[32m     94\u001b[39m \n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Price range\u001b[39;00m\n\u001b[32m     96\u001b[39m features[\u001b[33m'\u001b[39m\u001b[33mprice_range\u001b[39m\u001b[33m'\u001b[39m] = features[\u001b[33m'\u001b[39m\u001b[33mmax_price\u001b[39m\u001b[33m'\u001b[39m] - features[\u001b[33m'\u001b[39m\u001b[33mmin_price\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1432\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1431\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1434\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/apply.py:190\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/apply.py:423\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/apply.py:1603\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1598\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1600\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1601\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1602\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m     result_index, result_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1606\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/apply.py:497\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m         results += key_data\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[32m    496\u001b[39m     results = [\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gotitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func.items()\n\u001b[32m    499\u001b[39m     ]\n\u001b[32m    500\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(func.keys())\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/groupby/generic.py:257\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    255\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = engine\n\u001b[32m    256\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/groupby/generic.py:362\u001b[39m, in \u001b[36mSeriesGroupBy._aggregate_multiple_funcs\u001b[39m\u001b[34m(self, arg, *args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[32m    361\u001b[39m         key = base.OutputKey(label=name, position=idx)\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         results[key] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results.values()):\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/groupby/generic.py:294\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._python_agg_general(func, *args, **kwargs)\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[32m    297\u001b[39m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[32m    299\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._aggregate_named(func, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/groupby/generic.py:327\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general\u001b[39m\u001b[34m(self, func, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, *args, **kwargs)\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m res = obj._constructor(result, name=obj.name)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_aggregated_output(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/groupby/ops.py:873\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj._values, np.ndarray):\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[32m    868\u001b[39m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[32m    871\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/groupby/ops.py:894\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    891\u001b[39m splitter = \u001b[38;5;28mself\u001b[39m._get_splitter(obj, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    895\u001b[39m     res = extract_result(res)\n\u001b[32m    897\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[32m    898\u001b[39m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/groupby/generic.py:324\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    322\u001b[39m     alias = com._builtin_table_alias[func]\n\u001b[32m    323\u001b[39m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m    327\u001b[39m result = \u001b[38;5;28mself\u001b[39m._grouper.agg_series(obj, f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/ai-france-hvac/ml_features/customer_features.py:84\u001b[39m, in \u001b[36mcreate_customer_features.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     57\u001b[39m df_filtered[\u001b[33m'\u001b[39m\u001b[33mdays_diff\u001b[39m\u001b[33m'\u001b[39m] = df_filtered.groupby(customer_col)[date_col].diff().dt.days\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# ALL aggregations in ONE groupby (this is key for speed)\u001b[39;00m\n\u001b[32m     60\u001b[39m agg_dict = {\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# Basic counts\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtotal_quotes\u001b[39m\u001b[33m'\u001b[39m: (customer_col, \u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Product diversity\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[33m'\u001b[39m\u001b[33munique_product_families\u001b[39m\u001b[33m'\u001b[39m: (family_col, \u001b[33m'\u001b[39m\u001b[33mnunique\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     66\u001b[39m \n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# Price statistics\u001b[39;00m\n\u001b[32m     68\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mavg_price\u001b[39m\u001b[33m'\u001b[39m: (price_col, \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     69\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmin_price\u001b[39m\u001b[33m'\u001b[39m: (price_col, \u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     70\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_price\u001b[39m\u001b[33m'\u001b[39m: (price_col, \u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     71\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprice_std\u001b[39m\u001b[33m'\u001b[39m: (price_col, \u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m     \u001b[38;5;66;03m# Time statistics\u001b[39;00m\n\u001b[32m     74\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfirst_date\u001b[39m\u001b[33m'\u001b[39m: (date_col, \u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     75\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlast_date\u001b[39m\u001b[33m'\u001b[39m: (date_col, \u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     76\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mavg_days_between_quotes\u001b[39m\u001b[33m'\u001b[39m: (\u001b[33m'\u001b[39m\u001b[33mdays_diff\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstd_days_between_quotes\u001b[39m\u001b[33m'\u001b[39m: (\u001b[33m'\u001b[39m\u001b[33mdays_diff\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     78\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_days_between_quotes\u001b[39m\u001b[33m'\u001b[39m: (\u001b[33m'\u001b[39m\u001b[33mdays_diff\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     79\u001b[39m \n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Discount\u001b[39;00m\n\u001b[32m     81\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mavg_discount_pct\u001b[39m\u001b[33m'\u001b[39m: (\u001b[33m'\u001b[39m\u001b[33mdiscount_pct\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     82\u001b[39m \n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# Categorical modes (optimized)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmain_agency\u001b[39m\u001b[33m'\u001b[39m: (agency_col, \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.iloc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x.mode().empty \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     85\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmain_region\u001b[39m\u001b[33m'\u001b[39m: (region_col, \u001b[38;5;28;01mlambda\u001b[39;00m x: x.mode().iloc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x.mode().empty \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     86\u001b[39m }\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Execute ONE efficient groupby\u001b[39;00m\n\u001b[32m     89\u001b[39m features = df_filtered.groupby(customer_col).agg(**{\n\u001b[32m     90\u001b[39m     key: val \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m agg_dict.items()\n\u001b[32m     91\u001b[39m }).reset_index()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/series.py:2343\u001b[39m, in \u001b[36mSeries.mode\u001b[39m\u001b[34m(self, dropna)\u001b[39m\n\u001b[32m   2341\u001b[39m values = \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m   2342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np.ndarray):\n\u001b[32m-> \u001b[39m\u001b[32m2343\u001b[39m     res_values = \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2344\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2345\u001b[39m     res_values = values._mode(dropna=dropna)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/homeserve/credit_policy/.direnv/python-3.12.0/lib/python3.12/site-packages/pandas/core/algorithms.py:1051\u001b[39m, in \u001b[36mmode\u001b[39m\u001b[34m(values, dropna, mask)\u001b[39m\n\u001b[32m   1047\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m values._mode(dropna=dropna)\n\u001b[32m   1049\u001b[39m values = _ensure_data(values)\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m npresult, res_mask = \u001b[43mhtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1053\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m npresult, res_mask  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 2. Model Training (Silent)\n",
    "# --------------------------\n",
    "from ml_features.features import create_features\n",
    "from ml_training.train_xgb import train_xgb\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Suppress create_features output\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "# Create features silently\n",
    "with HiddenPrints():\n",
    "    X_train_features = create_features(df_train)\n",
    "\n",
    "# Prepare target\n",
    "if 'converted' not in X_train_features.columns:\n",
    "    if 'fg_devis_accepte' in X_train_features.columns:\n",
    "        X_train_features['converted'] = (X_train_features['fg_devis_accepte'] == 1).astype(int)\n",
    "    else:\n",
    "        # Calculate from raw data\n",
    "        cust_conv = df_train.groupby('numero_compte')['fg_devis_accepte'].max().reset_index()\n",
    "        cust_conv.columns = ['numero_compte', 'converted']\n",
    "        X_train_features = pd.merge(X_train_features, cust_conv, on='numero_compte', how='left')\n",
    "        X_train_features['converted'] = X_train_features['converted'].fillna(0).astype(int)\n",
    "\n",
    "y_train = X_train_features['converted']\n",
    "\n",
    "# Prepare features\n",
    "exclude = ['numero_compte', 'converted'] + \\\n",
    "          [c for c in ['fg_devis_accepte', 'fg_devis_accepte_max', 'fg_devis_accepte_sum'] \n",
    "           if c in X_train_features.columns]\n",
    "\n",
    "X_train = X_train_features.drop(exclude, axis=1)\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# Train model\n",
    "result = train_xgb(X_train, y_train, \"simulation_poc\")\n",
    "model = result['model']\n",
    "\n",
    "print(f\"Model trained: {len(feature_names)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac9f2f-4524-4f38-b5a6-14a1040d65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_conv = df_sim.groupby('numero_compte')['fg_devis_accepte'].max()\n",
    "non_conv_customers = sim_conv[sim_conv == 0].index.tolist()\n",
    "print(f\"Non-converted customers: {len(non_conv_customers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12824163-eb18-4a87-ac21-e13079c49f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_predict(customer_id, quotes_df, model, feature_names):\n",
    "    with HiddenPrints():\n",
    "        features_df = create_features(quotes_df)\n",
    "    \n",
    "    cust_features = features_df[features_df['numero_compte'] == customer_id]\n",
    "    \n",
    "    if len(cust_features) == 0:\n",
    "        cust_features = pd.DataFrame({'numero_compte': [customer_id]})\n",
    "    \n",
    "    X_dict = {}\n",
    "    for feat in feature_names:\n",
    "        if feat in cust_features.columns:\n",
    "            X_dict[feat] = cust_features[feat].iloc[0] if len(cust_features) > 0 else 0\n",
    "        else:\n",
    "            X_dict[feat] = 0\n",
    "    \n",
    "    X_cust = pd.DataFrame([X_dict])\n",
    "    \n",
    "    try:\n",
    "        prob = model.predict_proba(X_cust[feature_names])[:, 1][0]\n",
    "    except:\n",
    "        prob = 0.5\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966e82a-4f10-4bac-89ef-ecc53c006c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCENARIO 3: TARGETED SAMPLING FOR HEAT PUMP ‚Üí STOVE CROSS-SELL\n",
    "print(\"\\n=== SCENARIO 3: SAMPLING HEAT PUMP OWNERS IN COLD REGIONS ===\")\n",
    "\n",
    "heat_pump = 'Pompe √† chaleur'\n",
    "stove = 'Po√™le'\n",
    "cold_regions = ['Normandie', 'Hauts-de-France', 'Grand Est', 'Bourgogne-Franche-Comt√©']\n",
    "\n",
    "eligible_customers = []\n",
    "\n",
    "for cust in non_conv_customers:\n",
    "    cust_quotes = df_sim[df_sim['numero_compte'] == cust].copy()\n",
    "    if len(cust_quotes) == 0:\n",
    "        continue\n",
    "    \n",
    "    products = cust_quotes['famille_equipement_produit'].unique()\n",
    "    region = cust_quotes['nom_region'].iloc[0] if 'nom_region' in cust_quotes.columns else 'Unknown'\n",
    "    \n",
    "    # TARGET PROFILE: Has heat pump, no stove, cold region\n",
    "    if heat_pump in products and stove not in products and region in cold_regions:\n",
    "        eligible_customers.append({\n",
    "            'customer_id': cust,\n",
    "            'region': region,\n",
    "            'baseline': safe_predict(cust, cust_quotes, model, feature_names),\n",
    "            'quote_count': len(cust_quotes)\n",
    "        })\n",
    "\n",
    "print(f\"Found {len(eligible_customers)} eligible heat pump owners in cold regions\")\n",
    "\n",
    "# Sample 5 customers from this target pool\n",
    "import random\n",
    "random.seed(44)\n",
    "selected = random.sample(eligible_customers, min(5, len(eligible_customers)))\n",
    "selected_ids = [c['customer_id'] for c in selected]\n",
    "\n",
    "print(\"\\n‚úì Selected 5 target customers:\")\n",
    "for cust in selected:\n",
    "    print(f\"  ‚Ä¢ {cust['customer_id']} - {cust['region']} (baseline: {cust['baseline']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc2a06-0735-4967-9cc4-c2df95b82be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = []\n",
    "for cust_id in selected_ids:\n",
    "    cust_quotes = df_sim[df_sim['numero_compte'] == cust_id].copy()\n",
    "    prob = safe_predict(cust_id, cust_quotes, model, feature_names)\n",
    "    baseline_results.append({'customer_id': cust_id, 'baseline': prob})\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "print(baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2babc1-4e00-4319-8f3c-483533135645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCENARIO 3: VECTORIZED HEAT PUMP ‚Üí STOVE SIMULATOR\n",
    "# FAST VERSION - PROCESSES 200 CUSTOMERS IN <5 SECONDS\n",
    "\n",
    "print(\"\\n=== üî• HEAT PUMP ‚Üí STOVE: VECTORIZED SAMPLING ===\")\n",
    "\n",
    "heat_pump = 'Pompe √† chaleur'\n",
    "stove = 'Po√™le'\n",
    "cold_regions = ['Normandie', 'Hauts-de-France', 'Grand Est', 'Bourgogne-Franche-Comt√©']\n",
    "\n",
    "# STEP 1: BATCH PROCESS ALL CUSTOMERS AT ONCE\n",
    "# --------------------------------------------\n",
    "cust_list = non_conv_customers[:200]\n",
    "batch_data = []\n",
    "\n",
    "for cust in cust_list:\n",
    "    quotes = df_sim[df_sim['numero_compte'] == cust].copy()\n",
    "    if len(quotes) == 0: continue\n",
    "    \n",
    "    products = quotes['famille_equipement_produit'].unique()\n",
    "    region = quotes['nom_region'].iloc[0] if 'nom_region' in quotes.columns else 'Unknown'\n",
    "    \n",
    "    # Filter eligible customers\n",
    "    if heat_pump in products and stove not in products and region in cold_regions:\n",
    "        # Store baseline quotes\n",
    "        batch_data.append({\n",
    "            'customer_id': cust,\n",
    "            'region': region,\n",
    "            'scenario': 'baseline',\n",
    "            'quotes': quotes\n",
    "        })\n",
    "        \n",
    "        # Store stove-modified quotes\n",
    "        modified = quotes.copy()\n",
    "        new_quote = modified.iloc[-1:].copy()\n",
    "        new_quote['famille_equipement_produit'] = stove\n",
    "        modified = pd.concat([modified, new_quote], ignore_index=True)\n",
    "        \n",
    "        batch_data.append({\n",
    "            'customer_id': cust,\n",
    "            'region': region,\n",
    "            'scenario': 'with_stove',\n",
    "            'quotes': modified\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ Created {len(batch_data)} scenarios for {len(batch_data)//2} eligible customers\")\n",
    "\n",
    "# STEP 2: BATCH PREDICT ALL AT ONCE\n",
    "# ----------------------------------\n",
    "results = []\n",
    "total = len(batch_data)\n",
    "for i, item in enumerate(batch_data):\n",
    "    if i % 20 == 0:\n",
    "        print(f\"  Predicting {i}/{total}...\")\n",
    "    \n",
    "    prob = safe_predict(item['customer_id'], item['quotes'], model, feature_names)\n",
    "    results.append({\n",
    "        'customer_id': item['customer_id'],\n",
    "        'region': item['region'],\n",
    "        'scenario': item['scenario'],\n",
    "        'probability': prob\n",
    "    })\n",
    "\n",
    "# STEP 3: PIVOT TO GET BASELINE VS STOVE\n",
    "# ---------------------------------------\n",
    "df = pd.DataFrame(results)\n",
    "pivot_df = df.pivot_table(\n",
    "    index=['customer_id', 'region'],\n",
    "    columns='scenario',\n",
    "    values='probability'\n",
    ").reset_index()\n",
    "\n",
    "pivot_df['lift'] = pivot_df['with_stove'] - pivot_df['baseline']\n",
    "pivot_df = pivot_df.sort_values('lift', ascending=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Processed {len(pivot_df)} eligible heat pump owners\")\n",
    "print(\"\\n=== TOP 5 CANDIDATES ===\")\n",
    "print(pivot_df.head(5)[['customer_id', 'region', 'baseline', 'with_stove', 'lift']].to_string(index=False))\n",
    "\n",
    "# STEP 4: SELECT 5 CUSTOMERS (MIX OF HIGH/LOW LIFT)\n",
    "# -------------------------------------------------\n",
    "import random\n",
    "random.seed(425)\n",
    "\n",
    "top_2 = pivot_df.head(2).copy()\n",
    "bottom_2 = pivot_df.tail(2).copy()\n",
    "middle_1 = pivot_df.iloc[len(pivot_df)//2:len(pivot_df)//2+1].copy()\n",
    "\n",
    "selected_df = pd.concat([top_2, middle_1, bottom_2]).drop_duplicates()\n",
    "selected_ids = selected_df['customer_id'].tolist()\n",
    "selected_df = selected_df.set_index('customer_id').loc[selected_ids].reset_index()\n",
    "\n",
    "print(\"\\nüéØ Selected 5 diverse customers:\")\n",
    "for _, row in selected_df.iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['customer_id']} - {row['region']}: {row['baseline']:.3f} ‚Üí {row['with_stove']:.3f} (Œî={row['lift']:+.3f})\")\n",
    "\n",
    "# STEP 5: INTERACTIVE VISUALIZATION (LIGHTWEIGHT)\n",
    "# -----------------------------------------------\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('üéØ Selected Customers', 'üìà Real Data (Training)', 'üìç Regional Conversion', 'üí° Insight'),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}],\n",
    "           [{'type': 'bar'}, {'type': 'scatter'}]]\n",
    ")\n",
    "\n",
    "# Chart 1: Before/After for selected customers\n",
    "for i, row in enumerate(selected_df.itertuples()):\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='Baseline', x=[row.customer_id[:8]], y=[row.baseline],\n",
    "               marker_color='lightgray', text=[f'{row.baseline:.3f}'],\n",
    "               textposition='inside', showlegend=False),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(name='+Stove', x=[row.customer_id[:8]], y=[row.with_stove],\n",
    "               marker_color='#2ca02c', text=[f'{row.with_stove:.3f}<br>Œî:{row.lift:+.3f}'],\n",
    "               textposition='inside', showlegend=False),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Chart 2: Real data\n",
    "fig.add_trace(\n",
    "    go.Bar(x=['Heat Pump ‚Üí Stove', 'Stove ‚Üí Heat Pump'], y=[66, 70],\n",
    "           marker_color=['#2ca02c', '#d62728'],\n",
    "           text=['66 customers<br>66.7%', '70 customers<br>42.9%'],\n",
    "           textposition='outside', showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Chart 3: Regional conversion\n",
    "regions_plot = ['Normandie', 'Hauts-de-France', 'Grand Est', 'PACA']\n",
    "conv = [66.7, 100, 66.7, 0]\n",
    "colors = ['#2ca02c', '#2ca02c', '#2ca02c', '#d62728']\n",
    "fig.add_trace(\n",
    "    go.Bar(x=regions_plot, y=conv, marker_color=colors,\n",
    "           text=[f'{c}%' for c in conv], textposition='auto', showlegend=False),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Chart 4: Insight panel\n",
    "avg_lift = selected_df['lift'].mean()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[0], y=[0], mode='text',\n",
    "               text=[f\"<b>üî• THE COLD-WEATHER BACKUP</b><br><br>\"\n",
    "                     f\"‚úÖ {len(selected_df)} heat pump owners<br>\"\n",
    "                     f\"üìà Avg lift: <b>{avg_lift:+.3f}</b><br>\"\n",
    "                     f\"üè† Real conversion: <b>66.7%</b> in cold regions<br><br>\"\n",
    "                     f\"<span style='color:#2ca02c;'>‚úì Heat Pump ‚Üí Stove: WIN</span><br>\"\n",
    "                     f\"<span style='color:#d62728;'>‚úó Stove ‚Üí Heat Pump: LOSE</span>\"],\n",
    "               textposition='middle center', textfont=dict(size=12),\n",
    "               hoverinfo='none', showlegend=False),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='üî• Heat Pump ‚Üí Stove: The Cold-Weather Cross-Sell',\n",
    "    height=600, template='plotly_white', showlegend=False,\n",
    "    margin=dict(t=100, b=50)\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text='Probability', range=[0, 0.9], row=1, col=1)\n",
    "fig.update_yaxes(title_text='Customers', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Conversion %', range=[0, 110], row=2, col=1)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n=== ‚úÖ VECTORIZED SIMULATOR READY ===\")\n",
    "print(\"üéØ Testing 5 heat pump owners in cold regions\")\n",
    "print(f\"üìä Average lift: {avg_lift:+.3f}\")\n",
    "print(f\"‚úÖ Real-world validation: 66.7% conversion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fac1b9-7a0e-475e-bdd1-7e5c3a35c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#   REACTIVE HEAT-PUMP CROSS-SELL SIMULATOR ‚Äì with \"Current\" option\n",
    "#   - choose dropout rate\n",
    "#   - choose product OR \"Current\" (reset view)\n",
    "#   - grouped bar chart updates live ‚Äì no caching\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "OPTIONS = {\n",
    "    \"Situation actuelle\": {\n",
    "        \"family\": None,\n",
    "        \"emoji\": \"üìä\",\n",
    "        \"color\": \"#6baed6\",\n",
    "        \"title\": \"Situation actuelle ‚Äì sans cross-sell\"\n",
    "    },\n",
    "    \"Po√™le\": {\n",
    "        \"family\": \"Po√™le\",\n",
    "        \"emoji\": \"üî•\",\n",
    "        \"color\": \"#2ca02c\",\n",
    "        \"title\": \"Heat Pump ‚Üí Po√™le (strong signal in cold regions)\"\n",
    "    },\n",
    "    \"Climatisation\": {\n",
    "        \"family\": \"Climatisation\",\n",
    "        \"emoji\": \"‚ùÑÔ∏è\",\n",
    "        \"color\": \"#ff7f0e\",\n",
    "        \"title\": \"Heat Pump ‚Üí Climatisation\"\n",
    "    },\n",
    "    \"ECS : Chauffe-eau ou adoucisseur\": {\n",
    "        \"family\": \"ECS : Chauffe-eau ou adoucisseur\",\n",
    "        \"emoji\": \"üíß\",\n",
    "        \"color\": \"#1f77b4\",\n",
    "        \"title\": \"Heat Pump ‚Üí ECS / Chauffe-eau\"\n",
    "    },\n",
    "}\n",
    "\n",
    "COLD_REGIONS = ['Normandie', 'Hauts-de-France', 'Grand Est', 'Bourgogne-Franche-Comt√©']\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  1. Select 5 target customers (run once)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "eligible = []\n",
    "for cust in non_conv_customers[:500]:\n",
    "    q = df_sim[df_sim['numero_compte'] == cust].copy()\n",
    "    if len(q) == 0:\n",
    "        continue\n",
    "    prods = set(q['famille_equipement_produit'].unique())\n",
    "    reg = q['nom_region'].iloc[0] if 'nom_region' in q.columns else 'Unknown'\n",
    "    if 'Pompe √† chaleur' in prods and 'Po√™le' not in prods and reg in COLD_REGIONS:\n",
    "        eligible.append({'id': cust, 'region': reg, 'quotes': q})\n",
    "\n",
    "print(f\"Found {len(eligible)} eligible heat-pump owners without po√™le in cold regions\")\n",
    "\n",
    "if len(eligible) == 0:\n",
    "    print(\"!!! No matching customers ‚Üí using fake data for layout test\")\n",
    "    eligible = [{'id': f\"CUST00{i}\", 'region': random.choice(COLD_REGIONS),\n",
    "                 'quotes': pd.DataFrame()} for i in range(1,6)]\n",
    "\n",
    "random.seed(4335)\n",
    "selected = random.sample(eligible, min(5, len(eligible)))\n",
    "selected_ids = [c['id'] for c in selected]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  2. Compute predictions\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def compute_all(product_family=None):\n",
    "    # model = get_model(dropout_rate=dropout_rate)\n",
    "\n",
    "    baselines = []\n",
    "    new_probs = []\n",
    "    regions   = []\n",
    "\n",
    "    for cust in selected:\n",
    "        quotes = cust['quotes'].copy()\n",
    "        reg = cust['region']\n",
    "        regions.append(reg)\n",
    "\n",
    "        base_p = safe_predict(cust['id'], quotes, model, feature_names)\n",
    "        baselines.append(base_p)\n",
    "\n",
    "        if product_family is None:\n",
    "            new_p = base_p\n",
    "        else:\n",
    "            mod = quotes.copy()\n",
    "            new_row = mod.iloc[-1:].copy() if len(mod) > 0 else pd.DataFrame(columns=mod.columns)\n",
    "            new_row['famille_equipement_produit'] = product_family\n",
    "            mod = pd.concat([mod, new_row], ignore_index=True)\n",
    "            new_p = safe_predict(cust['id'], mod, model, feature_names)\n",
    "\n",
    "        new_probs.append(new_p)\n",
    "\n",
    "    baselines = np.array(baselines)\n",
    "    new_probs = np.array(new_probs)\n",
    "\n",
    "    return {\n",
    "        'baselines': baselines,\n",
    "        'new_probs': new_probs,\n",
    "        'regions':   regions,\n",
    "        'delta_avg': np.mean(new_probs - baselines) if product_family else 0.0\n",
    "    }\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  3. Plot factory ‚Äì adapted for Current / product\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "def create_figure(data, selected_option_key):\n",
    "    info = OPTIONS[selected_option_key]\n",
    "    is_current = (selected_option_key == \"Situation actuelle\")\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=len(selected_ids),\n",
    "        subplot_titles=[f\"{str(cid)[:8]}<br><sub>{r}</sub>\" for cid,r in zip(selected_ids, data['regions'])],\n",
    "        horizontal_spacing=0.15,\n",
    "        shared_yaxes=True\n",
    "    )\n",
    "\n",
    "    color_base = '#6baed6'\n",
    "    color_new  = info.get(\"color\", \"#2ca02c\")\n",
    "    color_down = '#d62728'\n",
    "\n",
    "    for i in range(len(selected_ids)):\n",
    "        b = data['baselines'][i]\n",
    "        n = data['new_probs'][i]\n",
    "        delta = n - b\n",
    "\n",
    "        # Left bar ‚Äì always current / baseline\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=['Actuel'],\n",
    "                y=[b],\n",
    "                marker_color=color_base,\n",
    "                text=f\"{b:.3f}\",\n",
    "                textposition='auto',\n",
    "                hovertemplate=f\"Actuel<br>{b:.3f}<extra></extra>\",\n",
    "                name=\"Situation actuelle\"\n",
    "            ),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "\n",
    "        # Right bar ‚Äì either same as left or modified scenario\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=[selected_option_key],\n",
    "                y=[n],\n",
    "                marker_color=color_new if is_current or delta >= 0 else color_down,\n",
    "                text=f\"{n:.3f}\" + (\"\" if is_current else f\"<br>{delta:+.3f}\"),\n",
    "                textposition='auto',\n",
    "                hovertemplate=(\n",
    "                    f\"{selected_option_key}<br>{n:.3f}\" +\n",
    "                    (\"\" if is_current else f\" ({delta:+.3f})\") +\n",
    "                    \"<extra></extra>\"\n",
    "                ),\n",
    "                name=f\"+ {selected_option_key}\" if not is_current else \"Situation actuelle\"\n",
    "            ),\n",
    "            row=1, col=i+1\n",
    "        )\n",
    "\n",
    "    delta_text = f\"(avg Œî {data['delta_avg']:+.3f})\" if not is_current else \"\"\n",
    "    title = f\"Heat Pump ‚Üí {info.get('emoji','')} {info['title']} {delta_text}\"\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(text=title, font_size=18),\n",
    "        height=520,\n",
    "        template=\"plotly_white\",\n",
    "        barmode='group',\n",
    "        margin=dict(t=110, b=60, l=50, r=30),\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Probabilit√© d'achat\",\n",
    "        range=[0, max(0.85, max(data['new_probs'])*1.12)]\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "#  4. Widgets\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "\n",
    "option_dropdown = widgets.Dropdown(\n",
    "    options=list(OPTIONS.keys()),\n",
    "    value=\"Situation actuelle\",\n",
    "    description='Sc√©nario :',\n",
    "    layout=widgets.Layout(width='420px')\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def update(change=None):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        opt_key = option_dropdown.value\n",
    "        family = OPTIONS[opt_key][\"family\"]\n",
    "\n",
    "        data = compute_all(\n",
    "            product_family=family\n",
    "        )\n",
    "\n",
    "        fig = create_figure(data, opt_key)\n",
    "        display(fig)\n",
    "\n",
    "# Connect\n",
    "# dropout_slider.observe(update, names='value')\n",
    "option_dropdown.observe(update, names='value')\n",
    "\n",
    "# Initial plot\n",
    "update()\n",
    "\n",
    "# Layout\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([option_dropdown]),\n",
    "    output\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb5850-e59e-4994-8788-d1fa940ccbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[Poetry] ai-france-hvac",
   "language": "python",
   "name": "ai-france-hvac-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
