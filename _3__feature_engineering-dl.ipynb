{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ccf8a2-cf1e-4f80-aaf6-62bd893f31ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Original quote data: 34,014 quotes from 23,888 customers\n",
      "\n",
      "================================================================================\n",
      "STRATEGY: CREATE FEATURES\n",
      "================================================================================\n",
      "Creating OPTIMIZED customer features (mode: first_conversion)...\n",
      "  Filtering post-first-purchase data...\n",
      "  Customers: 23,888, Quotes: 33,247\n",
      "  Calculating features...\n",
      "  Calculating price trajectory (optimized)...\n",
      "‚úì Created 14 leakage-free features\n",
      "‚Üí 23,888 customers | 39.6% converters\n",
      "‚è±Ô∏è  Execution time: 10.2 seconds\n",
      "‚ö†Ô∏è  10.2s (target was 3s)\n",
      "================================================================================\n",
      "CREATING FIRST CONVERSION PREDICTION FEATURES (LEAKAGE-FREE)\n",
      "================================================================================\n",
      "  Total customers: 23,888\n",
      "‚ö° Processing customers with corrected first-conversion logic...\n",
      "  Processed 0/23,888 customers\n",
      "  Processed 5,000/23,888 customers\n",
      "  Processed 10,000/23,888 customers\n",
      "  Processed 15,000/23,888 customers\n",
      "  Processed 20,000/23,888 customers\n",
      "‚úÖ First-conversion features calculation complete\n",
      "\n",
      "üîç VALIDATION REPORT:\n",
      "   Total customers: 23,888\n",
      "   First converters: 9,458 (39.6%)\n",
      "   Never converters: 14,430\n",
      "\n",
      "üìä Distribution check:\n",
      "   Converters with 0 historical quotes: 7,105\n",
      "   Non-converters with 0 historical quotes: 10,488\n",
      "   Avg historical quotes - Converters: 0.3\n",
      "   Avg historical quotes - Non-converters: 0.4\n",
      "\n",
      "‚úÖ LEAKAGE PREVENTION CONFIRMED:\n",
      "   1. No conversion rate features (would leak)\n",
      "   2. Same feature calculation for all customers\n",
      "   3. No post-first-conversion data used\n",
      "   4. Features use only pre-prediction-point data\n",
      "   5. Target variable name kept as 'converted' for compatibility\n",
      "23888\n",
      "================================================================================\n",
      "CREATING BRAND FEATURES (ULTRA-FAST, LEAKAGE-FREE)\n",
      "================================================================================\n",
      "Processing 34,014 quotes for 23,888 customers\n",
      "üë• Single groupby aggregation...\n",
      "  Processing 23,888 customers with brand data\n",
      "‚ö° Vectorized feature calculation...\n",
      "‚úÖ Vectorized calculations complete\n",
      "üìù Creating final DataFrame...\n",
      "\n",
      "‚úÖ Created 8 brand features\n",
      "   Total customers: 23,888\n",
      "   With brand data: 23,888\n",
      "\n",
      "üìä FEATURE SUMMARY:\n",
      "--------------------------------------------------\n",
      "brand_loyalty_index       : mean = 0.923\n",
      "brand_switches            : mean = 0.186\n",
      "brand_consistency         : mean = 0.840\n",
      "prefers_premium_brand     : mean = 0.240\n",
      "prefers_budget_brand      : mean = 0.313\n",
      "23888\n",
      "================================================================================\n",
      "CREATING MODEL FEATURES (HYPER-FAST)\n",
      "================================================================================\n",
      "Processing 23,888 customers\n",
      "üë• Grouping and preprocessing...\n",
      "  Processing 23,888 customers\n",
      "‚ö° Hyper-fast calculations...\n",
      "‚úÖ Calculations complete\n",
      "üìù Creating final DataFrame...\n",
      "\n",
      "‚úÖ Created 14 model features\n",
      "   Customers: 23,888\n",
      "23888\n",
      "================================================================================\n",
      "CREATING LEAKAGE-FREE MARKET FEATURES\n",
      "================================================================================\n",
      "üö® FORCE REMOVING LEAKY BRANDS\n",
      "Found 23 leaky brands\n",
      "Found 23 near-perfect brands (‚â•99% or ‚â§1%)\n",
      "Total suspicious brands to remove: 23\n",
      "  - DEVILLE: 100.0% (1.0 quotes)\n",
      "  - THERMADOR: 100.0% (1.0 quotes)\n",
      "  - AOSMITH: 0.0% (1.0 quotes)\n",
      "  - HENRAD: 0.0% (2.0 quotes)\n",
      "  - WATTS: 0.0% (3.0 quotes)\n",
      "  - AIRZONE: 0.0% (1.0 quotes)\n",
      "  - FROLING: 0.0% (3.0 quotes)\n",
      "  - WILO: 0.0% (1.0 quotes)\n",
      "  - ABB: 0.0% (1.0 quotes)\n",
      "  - BRUGMAN: 0.0% (1.0 quotes)\n",
      "Replaced 37 quotes with 'SUSPICIOUS_BRAND'\n",
      "Remaining leaky brands after removal: 0\n",
      "Processing 34,014 quotes for 23,888 customers\n",
      "Using ALL quotes for market features (brand preferences are stable)\n",
      "  Quotes for feature calculation: 34,014\n",
      "üë• Grouping customer data...\n",
      "  Processing 23,888 customers with brand data\n",
      "‚ö° Calculating leakage-free features...\n",
      "‚úÖ Calculations complete\n",
      "üéØ Adding target variable...\n",
      "\n",
      "‚úÖ Created 7 leakage-free market features\n",
      "   Total customers: 23,888\n",
      "   With brand data: 23,888\n",
      "   Converters: 9,458 (39.6%)\n",
      "\n",
      "üîç DEBUG: Checking market_data_available distribution:\n",
      "   Converters with brand data: 9,458/9,458 (100.0%)\n",
      "   Non-converters with brand data: 14,430/14,430 (100.0%)\n",
      "   Ratio (should be ~similar): 1.000 vs 1.000\n",
      "\n",
      "üîç Feature correlations with target (should be < 0.3 for no leakage):\n",
      "   ‚úÖ premium_brand_ratio      : -0.038\n",
      "   ‚úÖ budget_brand_ratio       : 0.024\n",
      "   ‚úÖ brand_consistency        : -0.038\n",
      "   ‚úÖ brand_diversity_index    : 0.038\n",
      "23888\n",
      "================================================================================\n",
      "CREATING EQUIPMENT UPGRADE PATH FEATURES (LEAKAGE-SAFE VERSION)\n",
      "================================================================================\n",
      "üîç Applying first conversion filtering...\n",
      "‚ö†Ô∏è  No first_purchase_dates provided - using all data (RISKY!)\n",
      "Processing equipment upgrade data for 23,888 customers\n",
      "üîç Ensuring chronological order to prevent leakage...\n",
      "‚úÖ Data sorted chronologically by customer and date\n",
      "\n",
      "üìä Applying complexity and seasonality mappings...\n",
      "Customers with equipment data: 23,888\n",
      "\n",
      "üîß Computing group-by aggregations...\n",
      "üîÑ Merging aggregated features...\n",
      "‚ö° Computing derived features...\n",
      "‚ùå Removing leaking features: upgrade_trajectory_score, has_upgrade, has_downgrade\n",
      "üßπ Cleaning up missing values...\n",
      "\n",
      "‚úÖ Created 30 SAFE equipment upgrade features\n",
      "   Samples: 23,888 customers\n",
      "   REMOVED: upgrade_trajectory_score, has_upgrade, has_downgrade (potential leakage)\n",
      "   FIRST CONVERSION MODE: DISABLED\n",
      "\n",
      "üìä KEY UPGRADE FEATURES SUMMARY:\n",
      "------------------------------------------------------------\n",
      "equipment_family_consistency        : mean=0.929, std=0.256, non-zero=92.9%\n",
      "seasonal_equipment_mix              : mean=0.048, std=0.209, non-zero=5.1%\n",
      "equipment_maturity_level            : mean=0.321, std=0.087, non-zero=100.0%\n",
      "equipment_variety_index             : mean=0.071, std=0.256, non-zero=7.1%\n",
      "has_multi_season                    : mean=0.051, std=0.219, non-zero=5.1%\n",
      "early_technology_adopter            : mean=0.198, std=0.398, non-zero=19.8%\n",
      "23888\n",
      "================================================================================\n",
      "CREATING SOLUTION COMPLEXITY FEATURES (VECTORIZED)\n",
      "================================================================================\n",
      "üîç Applying first conversion filtering...\n",
      "‚ö†Ô∏è  No first_purchase_dates provided - using all data\n",
      "Processing solution complexity for 23,888 customers\n",
      "üîç Ensuring chronological order...\n",
      "‚úÖ Data sorted chronologically by customer and date\n",
      "\n",
      "üìä Preparing data for vectorized processing...\n",
      "Processing 34,014 equipment records\n",
      "üîß Creating system type indicators...\n",
      "üìà Computing aggregated features...\n",
      "‚ö° Calculating complexity scores...\n",
      "üå± Calculating energy efficiency...\n",
      "üîó Computing system integration...\n",
      "üèÜ Determining primary systems...\n",
      "üîÑ Merging all features...\n",
      "üìä Calculating sophistication tiers...\n",
      "\n",
      "‚úÖ Created 27 solution complexity features\n",
      "   Samples: 23,888 customers\n",
      "   FIRST CONVERSION MODE: DISABLED\n",
      "\n",
      "üìä SOLUTION COMPLEXITY FEATURES SUMMARY:\n",
      "------------------------------------------------------------\n",
      "multi_system_count                  : mean=0.936, std=0.313\n",
      "solution_complexity_score           : mean=2.717, std=0.940\n",
      "has_complete_heating_solution       : mean=0.000, std=0.000\n",
      "energy_efficiency_score             : mean=0.800, std=1.858\n",
      "system_integration_level            : mean=0.017, std=0.123\n",
      "primary_system_dominance            : mean=0.968, std=0.119\n",
      "sophistication_score                : mean=0.972, std=0.756\n",
      "future_proofing_score               : mean=0.054, std=0.108\n",
      "23888\n",
      "================================================================================\n",
      "CREATING TIMELINE FEATURES (mode: first_conversion)\n",
      "================================================================================\n",
      "Using date column: 'dt_creation_devis'\n",
      "Processing 23,888 customers\n",
      "\n",
      "üîß NO FILTERING: Using ALL quotes for timeline features\n",
      "   (Like market features, timeline patterns are stable characteristics)\n",
      "   Quotes for features: 34,014\n",
      "\n",
      "üéØ Adding target variable...\n",
      "\n",
      "üö® VERIFICATION: Data availability (should be ~100% for both)\n",
      "  Converters with data: 100.0%\n",
      "  Non-converters with data: 100.0%\n",
      "  Difference: 0.0% (should be < 10%)\n",
      "\n",
      "‚úÖ Created 20 timeline features\n",
      "   Total customers: 23,888\n",
      "   Converters: 9,458 (39.6%)\n",
      "23888\n",
      "================================================================================\n",
      "CREATING ADVANCED TIMELINE FEATURES (mode: first_conversion)\n",
      "================================================================================\n",
      "Initial data: 34,014 quotes for 23,888 customers\n",
      "\n",
      "üîß NO FILTERING: Using ALL quotes for advanced timeline features\n",
      "   (Like basic timeline and market features)\n",
      "   Quotes for features: 34,014\n",
      "\n",
      "üéØ Adding target variable...\n",
      "\n",
      "‚úÖ Created advanced timeline features for 23,888 customers\n",
      "   With data: 23,888\n",
      "   Converters: 9,458 (39.6%)\n",
      "\n",
      "üö® VERIFICATION: Data balance\n",
      "   Converters with data: 100.0%\n",
      "   Non-converters with data: 100.0%\n",
      "   Difference: 0.0%\n",
      "23888\n",
      "üîç Applying first conversion filtering...\n",
      "‚ö†Ô∏è  No first_purchase_dates provided - using all data\n",
      "‚úÖ Created 3 LEAKAGE-SAFE commercial features\n",
      "   REMOVED: total_quotes, unique_roles, senior_commercial_count (potential leakage)\n",
      "   FIRST CONVERSION MODE: DISABLED\n",
      "23888\n",
      "================================================================================\n",
      "üöÄ ULTRA-FAST CUSTOMER-LEVEL PROCESS FEATURES\n",
      "================================================================================\n",
      "Processing 34,014 quotes for 23,888 customers\n",
      "üë• Vectorized aggregation...\n",
      "‚ö° Vectorized feature calculation...\n",
      "  ‚Üí Creating derived features...\n",
      "üìù Finalizing features...\n",
      "\n",
      "‚úÖ Created 11 process features for 23,888 customers\n",
      "‚è±Ô∏è  Execution time: 4.26 seconds\n",
      "\n",
      "üìä FEATURE SUMMARY:\n",
      "--------------------------------------------------\n",
      "Adoption Rate             : mean = 0.567, std = 0.489\n",
      "Ever Used (%)             : 57.9%\n",
      "Consistency               : mean = 0.974, std = 0.158\n",
      "Confidence Score          : mean = 0.811, std = 0.219\n",
      "23888\n",
      "Creating features from raw data with error correction...\n",
      "  ‚Üí Single groupby for all features...\n",
      "  ‚Üí Vectorized calculations...\n",
      "  ‚Üí Optimized decision speed features...\n",
      "  ‚Üí Additional features...\n",
      "  ‚Üí Final cleanup...\n",
      "‚úÖ Created 32 optimized features for 23888 customers\n",
      "   Columns: ['numero_compte', 'total_quotes', 'unique_agencies', 'unique_equipment', 'unique_brands', 'avg_price', 'max_price', 'min_price', 'new_process_count', 'unique_commercials', 'engagement_days', 'engagement_density', 'is_single_quote', 'new_process_ratio', 'process_consistency', 'price_range', 'price_volatility', 'primary_equipment', 'primary_brand', 'avg_days_between', 'std_days_between', 'min_days_between', 'max_days_between', 'is_quick_decider', 'optimal_timing_score', 'tire_kicker_indicator', 'engagement_consistency', 'is_senior_commercial', 'agency_switches', 'price_consistency_score', 'equipment_focus_score', 'brand_loyalty_score', 'converted']\n",
      "   Dtypes: [dtype('O') dtype('int64') dtype('float64')]\n",
      "23888\n",
      "\n",
      "üîß ENCODING & PREPARING FOR MODELING...\n",
      "  Preparing Customer Features...\n",
      "  Features: 14, Samples: 23888\n",
      "\n",
      "üîß ENCODING & PREPARING FOR MODELING...\n",
      "  Preparing Sequence Features...\n",
      "  Features: 29, Samples: 23888\n",
      "\n",
      "üîß ENCODING & PREPARING FOR MODELING...\n",
      "  Preparing New Features...\n",
      "  Features: 180, Samples: 23888\n",
      "\n",
      "================================================================================\n",
      "CREATING SAFE DL-OPTIMIZED FEATURES (V2)\n",
      "================================================================================\n",
      "üìä Input shape: (23888, 180)\n",
      "üìã Found 180 numeric columns\n",
      "\n",
      "üîß Step 1: Scaling features to reasonable range...\n",
      "\n",
      "üîß Step 2: Adding safe transformations to ALL numeric features...\n",
      "\n",
      "üîß Step 3: Adding safe interactions...\n",
      "    ‚úì Added interaction: std_days_between_quotes / price_trajectory\n",
      "\n",
      "üîß Step 4: Clipping all features to safe range...\n",
      "\n",
      "‚úÖ SAFE DL Features Created:\n",
      "  Original: 180 features\n",
      "  Final: 721 features\n",
      "  Added: 541 new features\n",
      "\n",
      "üìä Safe value ranges:\n",
      "  Min: -10.00\n",
      "  Max: 10.00\n",
      "  Mean: 0.14\n",
      "\n",
      "üöÄ Training ADVANCED DL Model...\n",
      "üîß Normalizing features for DL...\n",
      "  Before: min=-10.00, max=10.00\n",
      "  Before: mean=0.14, std=0.79\n",
      "  After: min=-6.17, max=6.60\n",
      "  After: mean=0.59, std=1.73\n",
      "  Normalization complete!\n",
      "üîß Normalizing features for DL...\n",
      "  Before: min=-10.00, max=10.00\n",
      "  Before: mean=0.14, std=0.79\n",
      "  After: min=-2.38, max=9.94\n",
      "  After: mean=0.73, std=1.95\n",
      "  Normalization complete!\n",
      "  Parameters: 320,018\n",
      "  Model: advanced\n",
      "  Input dim: 721\n",
      "  Parameters: 320,018\n",
      "  Training samples: 19,110\n",
      "  Validation samples: 4,778\n",
      "  ‚úì Epoch 1: Loss=0.9283, Val AUC=0.6686\n",
      "  ‚úì Epoch 2: Loss=0.8345, Val AUC=0.6878\n",
      "  ‚úì Epoch 3: Loss=0.8018, Val AUC=0.6954\n",
      "  ‚úì Epoch 4: Loss=0.7765, Val AUC=0.7019\n",
      "  ‚úì Epoch 5: Loss=0.7607, Val AUC=0.7044\n",
      "  ‚úì Epoch 6: Loss=0.7530, Val AUC=0.7072\n",
      "  ‚úì Epoch 7: Loss=0.7421, Val AUC=0.7119\n",
      "  ‚úì Epoch 8: Loss=0.7372, Val AUC=0.7131\n",
      "  ‚úì Epoch 9: Loss=0.7352, Val AUC=0.7147\n",
      "  ‚úì Epoch 10: Loss=0.7347, Val AUC=0.7155\n",
      "  ‚úì Epoch 12: Loss=0.7206, Val AUC=0.7176\n",
      "  ‚úì Epoch 13: Loss=0.7192, Val AUC=0.7186\n",
      "  ‚úì Epoch 16: Loss=0.7083, Val AUC=0.7193\n",
      "  ‚èπÔ∏è Early stopping at epoch 41\n",
      "\n",
      "‚úÖ Training Complete!\n",
      "  Best Val AUC: 0.7193\n",
      "‚úì Model saved: dl_advanced_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from etl.util import prepare_dataset_without_leakage\n",
    "from ml_features.features import prepare_features\n",
    "from ml_features.customer_features import create_customer_features\n",
    "from ml_features.sequence_features  import create_sequence_features\n",
    "from ml_features.brand_features import create_brand_features\n",
    "from ml_features.model_features import create_model_features\n",
    "from ml_features.market_features import create_market_features\n",
    "from ml_features.equipment_features import create_equipment_features\n",
    "from ml_features.solution_complexity_features import create_solution_complexity_features\n",
    "from ml_features.timeline_features import create_timeline_features, create_advanced_timeline_features, create_timeline_interaction_features\n",
    "from ml_features.role_features import create_commercial_role_features\n",
    "from ml_features.process_features import create_process_features\n",
    "from ml_features.correction_features import create_correction_features\n",
    "from ml_training.train_rf import train_rf\n",
    "from ml_evaluation.dashboard import model_evaluation_report\n",
    "from dl_evaluation.evaluation import analyze_input_feature_importance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load original clean quote data\n",
    "df_quotes = pd.read_csv('cleaned_quote_data.csv')\n",
    "df_quotes['dt_creation_devis'] = pd.to_datetime(df_quotes['dt_creation_devis'])\n",
    "\n",
    "print(f\"\\nüìä Original quote data: {len(df_quotes):,} quotes from {df_quotes['numero_compte'].nunique():,} customers\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY: CREATE FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create feature list\n",
    "feature_funcs = [create_customer_features, create_sequence_features, create_brand_features, \n",
    "                 create_model_features, create_market_features,\n",
    "                 create_equipment_features, create_solution_complexity_features,\n",
    "                 create_timeline_features, create_advanced_timeline_features,\n",
    "                 create_commercial_role_features, create_process_features, create_correction_features]\n",
    "\n",
    "\n",
    "new_df = feature_funcs[0](df_quotes)\n",
    "customer_df = new_df\n",
    "for func in feature_funcs[1:]:\n",
    "    new_df_ = func(df_quotes)\n",
    "\n",
    "    new_df = pd.merge(new_df, new_df_, on='numero_compte', how='left', suffixes=('_dup', ''))\n",
    "    new_df = new_df.drop(columns=[x for x in new_df.columns if '_dup' in x], errors='ignore')\n",
    "    print(len(new_df))\n",
    "    if func == create_sequence_features: sequence_df = new_df\n",
    "\n",
    "\n",
    "# Now it's clear which column is which\n",
    "y_new = new_df['converted']  # From sequence features\n",
    "y_sequence = sequence_df['converted']  # From sequence features\n",
    "y_customer = customer_df['converted']  # From customer features\n",
    "\n",
    "# For modeling, use the sequence version\n",
    "X_customer = customer_df.drop(columns=['numero_compte', 'converted'], errors='ignore')\n",
    "X_customer_clean, y_customer_clean = prepare_features(X_customer, y_customer, \"Customer Features\")\n",
    "\n",
    "columns_to_drop =  [x for x in sequence_df.columns if '_seq' in x]\n",
    "columns_to_drop.extend(['numero_compte', 'converted'])\n",
    "X_sequence = sequence_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "X_sequence_clean, y_sequence_clean = prepare_features(X_sequence, y_sequence, \"Sequence Features\")\n",
    "\n",
    "new_df = create_timeline_interaction_features(new_df)\n",
    "X_new = new_df.drop(columns=['numero_compte', 'converted'], errors='ignore')\n",
    "X_new_clean, y_new_clean = prepare_features(X_new, y_new, \"New Features\")\n",
    "\n",
    "from dl_training.train import train_advanced_dl_model\n",
    "from dl_features.features import create_dl_specific_features, create_focused_features, enhance_region_features, enhance_discount_features\n",
    "\n",
    "X_dl, y_dl = create_dl_specific_features(X_new_clean, y_new_clean)\n",
    "\n",
    "result = train_advanced_dl_model(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09520517-2b7a-41a6-852e-b9e9ccb5e213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GRADIENT-BASED INPUT FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "\n",
      "Top 20 input features by gradient magnitude:\n",
      "  total_historical_quotes_tanh             | Gradient: 0.464343\n",
      "  total_historical_quotes_abs_sqrt         | Gradient: 0.421016\n",
      "  total_historical_quotes_log              | Gradient: 0.375627\n",
      "  total_historical_quotes                  | Gradient: 0.345736\n",
      "  had_historical_quotes_tanh               | Gradient: 0.341350\n",
      "  had_historical_quotes                    | Gradient: 0.339938\n",
      "  min_price                                | Gradient: 0.306772\n",
      "  primary_brand_log                        | Gradient: 0.262006\n",
      "  min_price_tanh                           | Gradient: 0.260713\n",
      "  avg_price_tanh                           | Gradient: 0.255805\n",
      "  avg_current_price_tanh                   | Gradient: 0.249723\n",
      "  max_price_tanh                           | Gradient: 0.234198\n",
      "  avg_price_log                            | Gradient: 0.212739\n",
      "  main_region                              | Gradient: 0.203347\n",
      "  quote_count                              | Gradient: 0.198151\n",
      "  total_quotes_log                         | Gradient: 0.197800\n",
      "  max_price                                | Gradient: 0.193181\n",
      "  total_quotes_abs_sqrt                    | Gradient: 0.180308\n",
      "  avg_discount_pct_abs_sqrt                | Gradient: 0.164956\n",
      "  month_5_count_log                        | Gradient: 0.163211\n",
      "\n",
      "üîç FEATURE CATEGORY ANALYSIS:\n",
      "  Price     : 57 features | Avg importance: 0.075695\n",
      "  Quote     : 69 features | Avg importance: 0.080999\n",
      "  Day       : 57 features | Avg importance: 0.049410\n",
      "  Average   : 52 features | Avg importance: 0.060783\n",
      "  Std Dev   : 43 features | Avg importance: 0.038525\n",
      "  Trend     :  4 features | Avg importance: 0.042835\n",
      "  Ratio     : 77 features | Avg importance: 0.041546\n",
      "  Log       : 183 features | Avg importance: 0.047226\n",
      "  Tanh      : 180 features | Avg importance: 0.051727\n",
      "  Sqrt      : 180 features | Avg importance: 0.046293\n"
     ]
    }
   ],
   "source": [
    "model = result['model']\n",
    "X_test = result['X_test']\n",
    "importance_df = analyze_input_feature_importance(model, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[Poetry] ai-france-hvac",
   "language": "python",
   "name": "ai-france-hvac-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
