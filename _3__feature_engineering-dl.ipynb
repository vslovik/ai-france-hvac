{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ccf8a2-cf1e-4f80-aaf6-62bd893f31ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Original quote data: 34,014 quotes from 23,888 customers\n",
      "\n",
      "================================================================================\n",
      "STRATEGY: CREATE FEATURES\n",
      "================================================================================\n",
      "Creating OPTIMIZED customer features (mode: first_conversion)...\n",
      "  Filtering post-first-purchase data...\n",
      "  Customers: 23,888, Quotes: 33,247\n",
      "  Calculating features...\n",
      "  Calculating price trajectory (optimized)...\n",
      "‚úì Created 14 leakage-free features\n",
      "‚Üí 23,888 customers | 39.6% converters\n",
      "‚è±Ô∏è  Execution time: 10.6 seconds\n",
      "‚ö†Ô∏è  10.6s (target was 3s)\n",
      "================================================================================\n",
      "CREATING FIRST CONVERSION PREDICTION FEATURES (LEAKAGE-FREE)\n",
      "================================================================================\n",
      "  Total customers: 23,888\n",
      "‚ö° Processing customers with corrected first-conversion logic...\n",
      "  Processed 0/23,888 customers\n",
      "  Processed 5,000/23,888 customers\n",
      "  Processed 10,000/23,888 customers\n",
      "  Processed 15,000/23,888 customers\n",
      "  Processed 20,000/23,888 customers\n",
      "‚úÖ First-conversion features calculation complete\n",
      "\n",
      "üîç VALIDATION REPORT:\n",
      "   Total customers: 23,888\n",
      "   First converters: 9,458 (39.6%)\n",
      "   Never converters: 14,430\n",
      "\n",
      "üìä Distribution check:\n",
      "   Converters with 0 historical quotes: 7,105\n",
      "   Non-converters with 0 historical quotes: 10,488\n",
      "   Avg historical quotes - Converters: 0.3\n",
      "   Avg historical quotes - Non-converters: 0.4\n",
      "\n",
      "‚úÖ LEAKAGE PREVENTION CONFIRMED:\n",
      "   1. No conversion rate features (would leak)\n",
      "   2. Same feature calculation for all customers\n",
      "   3. No post-first-conversion data used\n",
      "   4. Features use only pre-prediction-point data\n",
      "   5. Target variable name kept as 'converted' for compatibility\n",
      "23888\n",
      "================================================================================\n",
      "CREATING BRAND FEATURES (ULTRA-FAST, LEAKAGE-FREE)\n",
      "================================================================================\n",
      "Processing 34,014 quotes for 23,888 customers\n",
      "üë• Single groupby aggregation...\n",
      "  Processing 23,888 customers with brand data\n",
      "‚ö° Vectorized feature calculation...\n",
      "‚úÖ Vectorized calculations complete\n",
      "üìù Creating final DataFrame...\n",
      "\n",
      "‚úÖ Created 8 brand features\n",
      "   Total customers: 23,888\n",
      "   With brand data: 23,888\n",
      "\n",
      "üìä FEATURE SUMMARY:\n",
      "--------------------------------------------------\n",
      "brand_loyalty_index       : mean = 0.923\n",
      "brand_switches            : mean = 0.186\n",
      "brand_consistency         : mean = 0.840\n",
      "prefers_premium_brand     : mean = 0.240\n",
      "prefers_budget_brand      : mean = 0.313\n",
      "23888\n",
      "================================================================================\n",
      "CREATING MODEL FEATURES (HYPER-FAST)\n",
      "================================================================================\n",
      "Processing 23,888 customers\n",
      "üë• Grouping and preprocessing...\n",
      "  Processing 23,888 customers\n",
      "‚ö° Hyper-fast calculations...\n",
      "‚úÖ Calculations complete\n",
      "üìù Creating final DataFrame...\n",
      "\n",
      "‚úÖ Created 14 model features\n",
      "   Customers: 23,888\n",
      "23888\n",
      "================================================================================\n",
      "CREATING LEAKAGE-FREE MARKET FEATURES\n",
      "================================================================================\n",
      "üö® FORCE REMOVING LEAKY BRANDS\n",
      "Found 23 leaky brands\n",
      "Found 23 near-perfect brands (‚â•99% or ‚â§1%)\n",
      "Total suspicious brands to remove: 23\n",
      "  - GIACOMINI: 0.0% (1.0 quotes)\n",
      "  - KERMI: 0.0% (1.0 quotes)\n",
      "  - GENERIC: 100.0% (1.0 quotes)\n",
      "  - AOSMITH: 0.0% (1.0 quotes)\n",
      "  - HENRAD: 0.0% (2.0 quotes)\n",
      "  - WATTS: 0.0% (3.0 quotes)\n",
      "  - THERMADOR: 100.0% (1.0 quotes)\n",
      "  - KALOR: 0.0% (4.0 quotes)\n",
      "  - DEVILLE: 100.0% (1.0 quotes)\n",
      "  - BRUGMAN: 0.0% (1.0 quotes)\n",
      "Replaced 37 quotes with 'SUSPICIOUS_BRAND'\n",
      "Remaining leaky brands after removal: 0\n",
      "Processing 34,014 quotes for 23,888 customers\n",
      "Using ALL quotes for market features (brand preferences are stable)\n",
      "  Quotes for feature calculation: 34,014\n",
      "üë• Grouping customer data...\n",
      "  Processing 23,888 customers with brand data\n",
      "‚ö° Calculating leakage-free features...\n",
      "‚úÖ Calculations complete\n",
      "üéØ Adding target variable...\n",
      "\n",
      "‚úÖ Created 7 leakage-free market features\n",
      "   Total customers: 23,888\n",
      "   With brand data: 23,888\n",
      "   Converters: 9,458 (39.6%)\n",
      "\n",
      "üîç DEBUG: Checking market_data_available distribution:\n",
      "   Converters with brand data: 9,458/9,458 (100.0%)\n",
      "   Non-converters with brand data: 14,430/14,430 (100.0%)\n",
      "   Ratio (should be ~similar): 1.000 vs 1.000\n",
      "\n",
      "üîç Feature correlations with target (should be < 0.3 for no leakage):\n",
      "   ‚úÖ premium_brand_ratio      : -0.038\n",
      "   ‚úÖ budget_brand_ratio       : 0.024\n",
      "   ‚úÖ brand_consistency        : -0.038\n",
      "   ‚úÖ brand_diversity_index    : 0.038\n",
      "23888\n",
      "================================================================================\n",
      "CREATING EQUIPMENT UPGRADE PATH FEATURES (LEAKAGE-SAFE VERSION)\n",
      "================================================================================\n",
      "üîç Applying first conversion filtering...\n",
      "‚ö†Ô∏è  No first_purchase_dates provided - using all data (RISKY!)\n",
      "Processing equipment upgrade data for 23,888 customers\n",
      "üîç Ensuring chronological order to prevent leakage...\n",
      "‚úÖ Data sorted chronologically by customer and date\n",
      "\n",
      "üìä Applying complexity and seasonality mappings...\n",
      "Customers with equipment data: 23,888\n",
      "\n",
      "üîß Computing group-by aggregations...\n",
      "üîÑ Merging aggregated features...\n",
      "‚ö° Computing derived features...\n",
      "‚ùå Removing leaking features: upgrade_trajectory_score, has_upgrade, has_downgrade\n",
      "üßπ Cleaning up missing values...\n",
      "\n",
      "‚úÖ Created 30 SAFE equipment upgrade features\n",
      "   Samples: 23,888 customers\n",
      "   REMOVED: upgrade_trajectory_score, has_upgrade, has_downgrade (potential leakage)\n",
      "   FIRST CONVERSION MODE: DISABLED\n",
      "\n",
      "üìä KEY UPGRADE FEATURES SUMMARY:\n",
      "------------------------------------------------------------\n",
      "equipment_family_consistency        : mean=0.929, std=0.256, non-zero=92.9%\n",
      "seasonal_equipment_mix              : mean=0.048, std=0.209, non-zero=5.1%\n",
      "equipment_maturity_level            : mean=0.321, std=0.087, non-zero=100.0%\n",
      "equipment_variety_index             : mean=0.071, std=0.256, non-zero=7.1%\n",
      "has_multi_season                    : mean=0.051, std=0.219, non-zero=5.1%\n",
      "early_technology_adopter            : mean=0.198, std=0.398, non-zero=19.8%\n",
      "23888\n",
      "================================================================================\n",
      "CREATING SOLUTION COMPLEXITY FEATURES (VECTORIZED)\n",
      "================================================================================\n",
      "üîç Applying first conversion filtering...\n",
      "‚ö†Ô∏è  No first_purchase_dates provided - using all data\n",
      "Processing solution complexity for 23,888 customers\n",
      "üîç Ensuring chronological order...\n",
      "‚úÖ Data sorted chronologically by customer and date\n",
      "\n",
      "üìä Preparing data for vectorized processing...\n",
      "Processing 34,014 equipment records\n",
      "üîß Creating system type indicators...\n",
      "üìà Computing aggregated features...\n",
      "‚ö° Calculating complexity scores...\n",
      "üå± Calculating energy efficiency...\n",
      "üîó Computing system integration...\n",
      "üèÜ Determining primary systems...\n",
      "üîÑ Merging all features...\n",
      "üìä Calculating sophistication tiers...\n",
      "\n",
      "‚úÖ Created 27 solution complexity features\n",
      "   Samples: 23,888 customers\n",
      "   FIRST CONVERSION MODE: DISABLED\n",
      "\n",
      "üìä SOLUTION COMPLEXITY FEATURES SUMMARY:\n",
      "------------------------------------------------------------\n",
      "multi_system_count                  : mean=0.936, std=0.313\n",
      "solution_complexity_score           : mean=2.717, std=0.940\n",
      "has_complete_heating_solution       : mean=0.000, std=0.000\n",
      "energy_efficiency_score             : mean=0.800, std=1.858\n",
      "system_integration_level            : mean=0.017, std=0.123\n",
      "primary_system_dominance            : mean=0.968, std=0.119\n",
      "sophistication_score                : mean=0.972, std=0.756\n",
      "future_proofing_score               : mean=0.054, std=0.108\n",
      "23888\n",
      "================================================================================\n",
      "CREATING TIMELINE FEATURES (mode: first_conversion)\n",
      "================================================================================\n",
      "Using date column: 'dt_creation_devis'\n",
      "Processing 23,888 customers\n",
      "\n",
      "üîß NO FILTERING: Using ALL quotes for timeline features\n",
      "   (Like market features, timeline patterns are stable characteristics)\n",
      "   Quotes for features: 34,014\n",
      "\n",
      "üéØ Adding target variable...\n",
      "\n",
      "üö® VERIFICATION: Data availability (should be ~100% for both)\n",
      "  Converters with data: 100.0%\n",
      "  Non-converters with data: 100.0%\n",
      "  Difference: 0.0% (should be < 10%)\n",
      "\n",
      "‚úÖ Created 20 timeline features\n",
      "   Total customers: 23,888\n",
      "   Converters: 9,458 (39.6%)\n",
      "23888\n",
      "================================================================================\n",
      "CREATING ADVANCED TIMELINE FEATURES (mode: first_conversion)\n",
      "================================================================================\n",
      "Initial data: 34,014 quotes for 23,888 customers\n",
      "\n",
      "üîß NO FILTERING: Using ALL quotes for advanced timeline features\n",
      "   (Like basic timeline and market features)\n",
      "   Quotes for features: 34,014\n",
      "\n",
      "üéØ Adding target variable...\n",
      "\n",
      "‚úÖ Created advanced timeline features for 23,888 customers\n",
      "   With data: 23,888\n",
      "   Converters: 9,458 (39.6%)\n",
      "\n",
      "üö® VERIFICATION: Data balance\n",
      "   Converters with data: 100.0%\n",
      "   Non-converters with data: 100.0%\n",
      "   Difference: 0.0%\n",
      "23888\n",
      "üîç Applying first conversion filtering...\n",
      "‚ö†Ô∏è  No first_purchase_dates provided - using all data\n",
      "‚úÖ Created 3 LEAKAGE-SAFE commercial features\n",
      "   REMOVED: total_quotes, unique_roles, senior_commercial_count (potential leakage)\n",
      "   FIRST CONVERSION MODE: DISABLED\n",
      "23888\n",
      "================================================================================\n",
      "üöÄ ULTRA-FAST CUSTOMER-LEVEL PROCESS FEATURES\n",
      "================================================================================\n",
      "Processing 34,014 quotes for 23,888 customers\n",
      "üë• Vectorized aggregation...\n",
      "‚ö° Vectorized feature calculation...\n",
      "  ‚Üí Creating derived features...\n",
      "üìù Finalizing features...\n",
      "\n",
      "‚úÖ Created 11 process features for 23,888 customers\n",
      "‚è±Ô∏è  Execution time: 4.38 seconds\n",
      "\n",
      "üìä FEATURE SUMMARY:\n",
      "--------------------------------------------------\n",
      "Adoption Rate             : mean = 0.567, std = 0.489\n",
      "Ever Used (%)             : 57.9%\n",
      "Consistency               : mean = 0.974, std = 0.158\n",
      "Confidence Score          : mean = 0.811, std = 0.219\n",
      "23888\n",
      "Creating features from raw data with error correction...\n",
      "  ‚Üí Single groupby for all features...\n",
      "  ‚Üí Vectorized calculations...\n",
      "  ‚Üí Optimized decision speed features...\n",
      "  ‚Üí Additional features...\n",
      "  ‚Üí Final cleanup...\n",
      "‚úÖ Created 32 optimized features for 23888 customers\n",
      "   Columns: ['numero_compte', 'total_quotes', 'unique_agencies', 'unique_equipment', 'unique_brands', 'avg_price', 'max_price', 'min_price', 'new_process_count', 'unique_commercials', 'engagement_days', 'engagement_density', 'is_single_quote', 'new_process_ratio', 'process_consistency', 'price_range', 'price_volatility', 'primary_equipment', 'primary_brand', 'avg_days_between', 'std_days_between', 'min_days_between', 'max_days_between', 'is_quick_decider', 'optimal_timing_score', 'tire_kicker_indicator', 'engagement_consistency', 'is_senior_commercial', 'agency_switches', 'price_consistency_score', 'equipment_focus_score', 'brand_loyalty_score', 'converted']\n",
      "   Dtypes: [dtype('O') dtype('int64') dtype('float64')]\n",
      "23888\n",
      "\n",
      "üîß ENCODING & PREPARING FOR MODELING...\n",
      "  Preparing Customer Features...\n",
      "  Features: 14, Samples: 23888\n",
      "\n",
      "üîß ENCODING & PREPARING FOR MODELING...\n",
      "  Preparing Sequence Features...\n",
      "  Features: 29, Samples: 23888\n",
      "================================================================================\n",
      "üîß COMPLETE PHASE B FEATURE ENGINEERING\n",
      "================================================================================\n",
      "\n",
      "1Ô∏è‚É£ CATBOOST INTERACTION FEATURES\n",
      "----------------------------------------\n",
      "\n",
      "2Ô∏è‚É£ EFFICIENCY-FOCUSED FEATURES\n",
      "----------------------------------------\n",
      "\n",
      "3Ô∏è‚É£ INTENT CLARITY FEATURES (From Roadmap)\n",
      "----------------------------------------\n",
      "\n",
      "4Ô∏è‚É£ BUDGET CERTAINTY FEATURES\n",
      "----------------------------------------\n",
      "\n",
      "‚úÖ PHASE B COMPLETE\n",
      "   Total new features created: 13\n",
      "   Total features in dataset: 195\n",
      "\n",
      "üìã FEATURE CATEGORIES:\n",
      "  ‚Ä¢ CatBoost Interactions: 4 features\n",
      "    - engagement_product_interaction\n",
      "    - historical_price_interaction\n",
      "    - quote_consistency_score\n",
      "    ... and 1 more\n",
      "  ‚Ä¢ Efficiency Focus: 5 features\n",
      "    - decision_efficiency_score\n",
      "    - is_short_cycle\n",
      "    - engagement_velocity\n",
      "    ... and 2 more\n",
      "  ‚Ä¢ Intent Clarity: 3 features\n",
      "    - equipment_consistency_score\n",
      "    - price_discovery_range\n",
      "    - price_consistency\n",
      "  ‚Ä¢ Budget Certainty: 1 features\n",
      "    - price_discovery_efficiency\n",
      "\n",
      "============================================================\n",
      "üéØ EFFICIENCY-FOCUSED FEATURE ENGINEERING\n",
      "============================================================\n",
      "\n",
      "‚úÖ Created 15 efficiency-focused features:\n",
      "  ‚Ä¢ decision_efficiency_score: quotes / days (efficiency)\n",
      "  ‚Ä¢ is_short_cycle: avg_days < 7 (short cycle)\n",
      "  ‚Ä¢ engagement_intensity: quotes √ó (1/days)\n",
      "  ‚Ä¢ is_very_short_cycle: avg_days < 3 (very short)\n",
      "  ‚Ä¢ solution_focus_score: 1/(variety √ó complexity)\n",
      "  ‚Ä¢ is_focused_shopper: low variety & complexity\n",
      "  ‚Ä¢ is_simple_solution: single equipment & simple\n",
      "  ‚Ä¢ price_discovery_efficiency: 1/(range √ó quotes)\n",
      "  ‚Ä¢ budget_certainty: 1 - range/max_price\n",
      "  ‚Ä¢ brand_efficiency: brand_loyalty_index\n",
      "  ‚Ä¢ brand_decision_efficiency: loyalty √ó (1 - switch_rate)\n",
      "  ‚Ä¢ learning_efficiency: current_quotes / historical_quotes\n",
      "  ‚Ä¢ is_experienced_shopper: has historical quotes\n",
      "  ‚Ä¢ equipment_consistency_score: 1/(equipment_variety + 1)\n",
      "  ‚Ä¢ price_discovery_range: max_price - min_price\n",
      "\n",
      "üìä FEATURE STATISTICS (first 5 new features):\n",
      "  ‚Ä¢ decision_efficiency_score: mean=1.057, std=0.560\n",
      "  ‚Ä¢ is_short_cycle: mean=0.893, std=0.309\n",
      "  ‚Ä¢ engagement_intensity: mean=1.057, std=0.560\n",
      "  ‚Ä¢ is_very_short_cycle: mean=0.871, std=0.335\n",
      "  ‚Ä¢ solution_focus_score: mean=0.310, std=0.211\n",
      "\n",
      "üìà Total features in dataset: 203\n",
      "üéØ New efficiency features: 15\n",
      "\n",
      "============================================================\n",
      "üéØ EFFICIENCY-FOCUSED FEATURE ENGINEERING\n",
      "============================================================\n",
      "\n",
      "üìà ADDING YOUR SUGGESTED FEATURES:\n",
      "  ‚úì engagement_speed_score\n",
      "  ‚úì engagement_consistency\n",
      "  ‚úì decision_complexity\n",
      "  ‚úì brand_consistency\n",
      "  ‚úì seasonal_engagement_ratio\n",
      "\n",
      "üîß ENCODING & PREPARING FOR MODELING...\n",
      "  Preparing New Features...\n",
      "  Features: 204, Samples: 23888\n",
      "\n",
      "================================================================================\n",
      "CREATING SAFE DL-OPTIMIZED FEATURES (V2)\n",
      "================================================================================\n",
      "üìä Input shape: (23888, 204)\n",
      "üìã Found 204 numeric columns\n",
      "\n",
      "üîß Step 1: Scaling features to reasonable range...\n",
      "\n",
      "üîß Step 2: Adding safe transformations to ALL numeric features...\n",
      "\n",
      "üîß Step 3: Adding safe interactions...\n",
      "    ‚úì Added interaction: std_days_between_quotes / price_trajectory\n",
      "\n",
      "üîß Step 4: Clipping all features to safe range...\n",
      "\n",
      "‚úÖ SAFE DL Features Created:\n",
      "  Original: 204 features\n",
      "  Final: 817 features\n",
      "  Added: 613 new features\n",
      "\n",
      "üìä Safe value ranges:\n",
      "  Min: -10.00\n",
      "  Max: 10.00\n",
      "  Mean: 0.15\n",
      "\n",
      "üöÄ Training ADVANCED DL Model...\n",
      "üîß Normalizing features for DL...\n",
      "  Before: min=-10.00, max=10.00\n",
      "  Before: mean=0.15, std=0.89\n",
      "  After: min=-6.17, max=6.60\n",
      "  After: mean=0.54, std=1.74\n",
      "  Normalization complete!\n",
      "üîß Normalizing features for DL...\n",
      "  Before: min=-10.00, max=10.00\n",
      "  Before: mean=0.15, std=0.89\n",
      "  After: min=-3.14, max=9.94\n",
      "  After: mean=0.74, std=1.92\n",
      "  Normalization complete!\n",
      "  Parameters: 356,978\n",
      "  Model: advanced\n",
      "  Input dim: 817\n",
      "  Parameters: 356,978\n",
      "  Training samples: 19,110\n",
      "  Validation samples: 4,778\n",
      "  ‚úì Epoch 1: Loss=0.8961, Val AUC=0.6875\n",
      "  ‚úì Epoch 2: Loss=0.8042, Val AUC=0.6983\n",
      "  ‚úì Epoch 3: Loss=0.7805, Val AUC=0.7067\n",
      "  ‚úì Epoch 4: Loss=0.7617, Val AUC=0.7159\n",
      "  ‚úì Epoch 6: Loss=0.7427, Val AUC=0.7160\n",
      "  ‚úì Epoch 7: Loss=0.7424, Val AUC=0.7219\n",
      "  ‚úì Epoch 10: Loss=0.7264, Val AUC=0.7229\n",
      "  ‚èπÔ∏è Early stopping at epoch 35\n",
      "\n",
      "‚úÖ Training Complete!\n",
      "  Best Val AUC: 0.7229\n",
      "‚úì Model saved: dl_advanced_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from etl.util import prepare_dataset_without_leakage\n",
    "from ml_features.features import prepare_features\n",
    "from ml_features.customer_features import create_customer_features\n",
    "from ml_features.sequence_features  import create_sequence_features\n",
    "from ml_features.brand_features import create_brand_features\n",
    "from ml_features.model_features import create_model_features\n",
    "from ml_features.market_features import create_market_features\n",
    "from ml_features.equipment_features import create_equipment_features\n",
    "from ml_features.solution_complexity_features import create_solution_complexity_features\n",
    "from ml_features.timeline_features import create_timeline_features, create_advanced_timeline_features, create_timeline_interaction_features\n",
    "from ml_features.role_features import create_commercial_role_features\n",
    "from ml_features.process_features import create_process_features\n",
    "from ml_features.correction_features import create_correction_features\n",
    "from ml_features.catboost_interaction_features import create_catboost_interaction_features\n",
    "from ml_features.efficiency_interation_features import create_efficiency_interaction_features\n",
    "from ml_features.engagement_interation_features import create_engagement_interaction_features\n",
    "from ml_training.train_rf import train_rf\n",
    "from ml_evaluation.dashboard import model_evaluation_report\n",
    "from dl_evaluation.evaluation import analyze_input_feature_importance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load original clean quote data\n",
    "df_quotes = pd.read_csv('cleaned_quote_data.csv')\n",
    "df_quotes['dt_creation_devis'] = pd.to_datetime(df_quotes['dt_creation_devis'])\n",
    "\n",
    "print(f\"\\nüìä Original quote data: {len(df_quotes):,} quotes from {df_quotes['numero_compte'].nunique():,} customers\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY: CREATE FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create feature list\n",
    "feature_funcs = [create_customer_features, create_sequence_features, create_brand_features, \n",
    "                 create_model_features, create_market_features,\n",
    "                 create_equipment_features, create_solution_complexity_features,\n",
    "                 create_timeline_features, create_advanced_timeline_features,\n",
    "                 create_commercial_role_features, create_process_features, create_correction_features]\n",
    "\n",
    "\n",
    "new_df = feature_funcs[0](df_quotes)\n",
    "customer_df = new_df\n",
    "for func in feature_funcs[1:]:\n",
    "    new_df_ = func(df_quotes)\n",
    "\n",
    "    new_df = pd.merge(new_df, new_df_, on='numero_compte', how='left', suffixes=('_dup', ''))\n",
    "    new_df = new_df.drop(columns=[x for x in new_df.columns if '_dup' in x], errors='ignore')\n",
    "    print(len(new_df))\n",
    "    if func == create_sequence_features: sequence_df = new_df\n",
    "\n",
    "\n",
    "# Now it's clear which column is which\n",
    "y_new = new_df['converted']  # From sequence features\n",
    "y_sequence = sequence_df['converted']  # From sequence features\n",
    "y_customer = customer_df['converted']  # From customer features\n",
    "\n",
    "# For modeling, use the sequence version\n",
    "X_customer = customer_df.drop(columns=['numero_compte', 'converted'], errors='ignore')\n",
    "X_customer_clean, y_customer_clean = prepare_features(X_customer, y_customer, \"Customer Features\")\n",
    "\n",
    "columns_to_drop =  [x for x in sequence_df.columns if '_seq' in x]\n",
    "columns_to_drop.extend(['numero_compte', 'converted'])\n",
    "X_sequence = sequence_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "X_sequence_clean, y_sequence_clean = prepare_features(X_sequence, y_sequence, \"Sequence Features\")\n",
    "\n",
    "new_df = create_timeline_interaction_features(new_df)\n",
    "new_df, _ = create_catboost_interaction_features(new_df)\n",
    "new_df, _ = create_efficiency_interaction_features(new_df)\n",
    "new_df, _ = create_engagement_interaction_features(new_df)\n",
    "\n",
    "X_new = new_df.drop(columns=['numero_compte', 'converted'], errors='ignore')\n",
    "X_new_clean, y_new_clean = prepare_features(X_new, y_new, \"New Features\")\n",
    "\n",
    "from dl_training.train import train_advanced_dl_model\n",
    "from dl_features.features import create_dl_specific_features, create_focused_features, enhance_region_features, enhance_discount_features\n",
    "\n",
    "X_dl, y_dl = create_dl_specific_features(X_new_clean, y_new_clean)\n",
    "\n",
    "result = train_advanced_dl_model(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09520517-2b7a-41a6-852e-b9e9ccb5e213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GRADIENT-BASED INPUT FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "\n",
      "Top 20 input features by gradient magnitude:\n",
      "  quote_consistency_score_abs_sqrt         | Gradient: 0.433054\n",
      "  learning_efficiency_abs_sqrt             | Gradient: 0.397036\n",
      "  quote_consistency_score_log              | Gradient: 0.321398\n",
      "  learning_efficiency_tanh                 | Gradient: 0.260537\n",
      "  learning_efficiency_log                  | Gradient: 0.252221\n",
      "  avg_discount_pct_tanh                    | Gradient: 0.213099\n",
      "  quote_consistency_score_tanh             | Gradient: 0.208117\n",
      "  max_price_tanh                           | Gradient: 0.189496\n",
      "  min_price_tanh                           | Gradient: 0.180432\n",
      "  min_price                                | Gradient: 0.172596\n",
      "  max_price                                | Gradient: 0.171000\n",
      "  main_region_tanh                         | Gradient: 0.169993\n",
      "  avg_discount_pct_abs_sqrt                | Gradient: 0.168233\n",
      "  avg_price                                | Gradient: 0.163623\n",
      "  avg_price_tanh                           | Gradient: 0.157352\n",
      "  month_4_count_tanh                       | Gradient: 0.154397\n",
      "  avg_discount_pct_log                     | Gradient: 0.150539\n",
      "  min_price_abs_sqrt                       | Gradient: 0.130661\n",
      "  peak_weekday_tanh                        | Gradient: 0.128966\n",
      "  prefers_budget_brand_log                 | Gradient: 0.128476\n",
      "\n",
      "üîç FEATURE CATEGORY ANALYSIS:\n",
      "  Price     : 77 features | Avg importance: 0.050406\n",
      "  Quote     : 77 features | Avg importance: 0.043539\n",
      "  Day       : 57 features | Avg importance: 0.033737\n",
      "  Average   : 52 features | Avg importance: 0.052531\n",
      "  Std Dev   : 43 features | Avg importance: 0.031884\n",
      "  Trend     :  4 features | Avg importance: 0.019364\n",
      "  Ratio     : 89 features | Avg importance: 0.029159\n",
      "  Log       : 207 features | Avg importance: 0.036272\n",
      "  Tanh      : 204 features | Avg importance: 0.037873\n",
      "  Sqrt      : 204 features | Avg importance: 0.039152\n"
     ]
    }
   ],
   "source": [
    "model = result['model']\n",
    "X_test = result['X_test']\n",
    "importance_df = analyze_input_feature_importance(model, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[Poetry] ai-france-hvac",
   "language": "python",
   "name": "ai-france-hvac-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
